<script lang="ts">
  import { onMount, onDestroy, createEventDispatcher } from 'svelte';
  import { FaceMesh } from '@mediapipe/face_mesh/face_mesh';
  import {
    drawConnectors,
    FACEMESH_TESSELATION,
    FACEMESH_RIGHT_EYE,
    FACEMESH_LEFT_EYE,
    FACEMESH_FACE_OVAL,
    FACEMESH_LIPS,
  } from '@mediapipe/drawing_utils/drawing_utils';
  import {
    PoseGuidanceDirection,
    PoseGuidanceType,
    POSE_GUIDANCE_MAP,
    type PoseGuidanceData,
  } from '../../../types/camera';
  import {
    ExpressionAnalyzer,
    type ExpressionData,
  } from '../../../lib/ExpressionAnalyzer';
  import {
    cameraConfig,
    poseTolerances,
    faceQualityThresholds,
    detectionTimingSettings,
    poseCalculationConfig,
    mediaPipeConfig,
  } from '../../../stores/cameraConfig';
  import { getDevicePitchAdjustment } from '../../../domain/cameraConfig';
  import type { CameraConfiguration } from '../../../domain/cameraConfig';
  import { MediaPipeAssetManager } from '../../../lib/MediaPipeAssetManager';

  const dispatch = createEventDispatcher();

  // Props
  export let videoElement: HTMLVideoElement | undefined = undefined;
  export let canvasElement: HTMLCanvasElement | undefined = undefined;
  export let showMesh: boolean = true;
  export let currentMode: string = 'idle';
  // mirrorMode ã¯ä½¿ç”¨ã—ãªã„ãŸã‚å‰Šé™¤

  // Constants
  export const CAPTURE_COUNT: number = 1;
  export let CaptureMode: any;
  export let enableExpressionDetection: boolean | undefined = undefined;

  // MediaPipe instances
  let faceMesh: any;
  let camera: any;
  let canvasCtx: CanvasRenderingContext2D | null = null;

  // Initialization state management
  let isStartingCamera = false;
  let isMediaPipeReady = false;
  let isCameraConfigReady = false;
  let isMediaPipeFullyInitialized = false;
  let hasProcessedFirstFrame = false;
  let initializationStep = 'idle'; // 'idle' | 'config' | 'mediapipe' | 'camera' | 'processing' | 'ready' | 'error'

  // Face detection state
  let faceDetectionCount = 0;
  let faceDetected = false;
  let faceDetectionStartTime: number | null = null;
  let faceLandmarks: any = null;

  // Expression analysis
  let expressionAnalyzer = new ExpressionAnalyzer();
  let currentExpression: ExpressionData | null = null;

  // Video dimensions for accurate coordinate transformation
  let currentVideoWidth = 0;
  let currentVideoHeight = 0;

  // Configuration from API (reactive)
  let config: CameraConfiguration;
  let FACE_DETECTION_THRESHOLD: number;
  let FACE_DETECTION_DELAY: number;
  let THRESHOLDS: { roll: number; pitch: number; yaw: number };
  let MIN_FACE_SIZE: number;
  let MIN_FACE_QUALITY: number;
  let GUIDANCE_UPDATE_INTERVAL: number;

  // Subscribe to camera configuration
  $: config = $cameraConfig.config;
  $: FACE_DETECTION_THRESHOLD =
    config.detectionTimingSettings.stabilityFrameCount;
  $: FACE_DETECTION_DELAY =
    config.detectionTimingSettings.autoCaptureDelaySeconds;
  $: THRESHOLDS = {
    roll: config.poseTolerances.rollDegrees,
    pitch: config.poseTolerances.pitchDegrees,
    yaw: config.poseTolerances.yawDegrees,
  };
  $: MIN_FACE_SIZE = config.faceQualityThresholds.minRelativeSize;
  $: MIN_FACE_QUALITY = config.faceQualityThresholds.minQualityScore;
  $: GUIDANCE_UPDATE_INTERVAL =
    config.detectionTimingSettings.guidanceUpdateIntervalMs;

  // Pose and stability tracking
  let stablePosition = false;
  let stableStartTime: number | null = null;
  let stableFrameCount = 0;
  let progress = 0;

  // Guidance
  let poseGuidanceMessage = '';
  let poseGuidanceType = '';
  let showPoseGuidance = false;
  let lastGuidanceUpdate = 0;
  let lastGuidanceMessage = '';

  // MediaPipeã‚¢ã‚»ãƒƒãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
  let assetManager: MediaPipeAssetManager;
  let localBlobUrls: string[] = []; // ä½œæˆã—ãŸBlob URLã‚’ç®¡ç†
  let preloadedUrls: Map<string, string> = new Map(); // äº‹å‰æº–å‚™ã—ãŸURL

  onMount(async () => {
    try {
      initializationStep = 'config';

      // ã‚¢ã‚»ãƒƒãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’åˆæœŸåŒ–
      assetManager = new MediaPipeAssetManager();
      await assetManager.init();

      // MediaPipeã‚¢ã‚»ãƒƒãƒˆã®URLã‚’äº‹å‰æº–å‚™
      await prepareMediaPipeAssets();

      // Ensure camera configuration is loaded first
      if (!$cameraConfig.isLoaded) {
        console.log('ğŸ“Š ã‚«ãƒ¡ãƒ©è¨­å®šã‚’èª­ã¿è¾¼ã¿ä¸­...');
        await cameraConfig.loadConfig();
        console.log('âœ… ã‚«ãƒ¡ãƒ©è¨­å®šã®èª­ã¿è¾¼ã¿å®Œäº†');
      }
      isCameraConfigReady = true;

      // Pre-initialize MediaPipe in background (don't wait for user action)
      initializationStep = 'mediapipe';
      console.log('ğŸ”§ MediaPipeã®äº‹å‰åˆæœŸåŒ–ã‚’é–‹å§‹...');
      await initializeMediaPipe();
      isMediaPipeReady = true;
      initializationStep = 'ready';
      console.log('âœ… MediaPipeã®äº‹å‰åˆæœŸåŒ–å®Œäº†ï¼ˆã‚«ãƒ¡ãƒ©èµ·å‹•å¾…æ©Ÿä¸­ï¼‰');
    } catch (error) {
      initializationStep = 'error';
      console.error('âŒ MediaPipeã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ');
      dispatch('error', {
        message:
          'ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚',
      });
    }
  });

  // Public method to reset detection state
  export function resetDetectionState() {
    // Reset all detection-related variables
    stablePosition = false;
    stableFrameCount = 0;
    lastGuidanceUpdate = 0;
    showPoseGuidance = false;
    poseGuidanceMessage = '';
    poseGuidanceType = '';

    // Reset expression analysis (only if enabled)
    if (enableExpressionDetection === true) {
      expressionAnalyzer.resetCalibration();
    }
    currentExpression = null;
  }

  onDestroy(() => {
    // Blob URLã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    localBlobUrls.forEach(url => URL.revokeObjectURL(url));
    localBlobUrls = [];
    preloadedUrls.clear();

    completeCleanup();
  });

  // Remove automatic camera starting - now controlled externally

  // Watch for mode changes (debug disabled)
  // $: if (currentMode) { console.log('ğŸ“± Mode changed:', currentMode); }

  // MediaPipeã‚¢ã‚»ãƒƒãƒˆã®URLã‚’äº‹å‰æº–å‚™
  async function prepareMediaPipeAssets() {
    // MediaPipeãŒå®Ÿéš›ã«èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦å«ã‚ã‚‹
    const requiredFiles = [
      'face_mesh_solution_packed_assets.data',
      'face_mesh_solution_simd_wasm_bin.wasm',
      'face_mesh_solution_packed_assets_loader.js',
      'face_mesh_solution_simd_wasm_bin.js', // loaderã‚¹ã‚¯ãƒªãƒ—ãƒˆ
      'face_mesh.binarypb', // ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿
    ];

    console.log('ğŸ”§ MediaPipeã‚¢ã‚»ãƒƒãƒˆã®äº‹å‰æº–å‚™ã‚’é–‹å§‹...');

    for (const file of requiredFiles) {
      try {
        // ã¾ãšãƒ­ãƒ¼ã‚«ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç¢ºèª
        let localUrl = await assetManager.createLocalFileUrl(file);

        if (localUrl) {
          console.log(`ğŸ¯ ãƒ­ãƒ¼ã‚«ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰äº‹å‰æº–å‚™: ${file}`);
          preloadedUrls.set(file, localUrl);
          localBlobUrls.push(localUrl);
        } else {
          // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã„å ´åˆã€CDNã‹ã‚‰ç›´æ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦Blob URLã‚’ä½œæˆ
          console.log(`ğŸ“¥ CDNã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: ${file}`);
          const cdnUrl = `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;

          try {
            const response = await fetch(cdnUrl);
            if (!response.ok) {
              throw new Error(
                `HTTP ${response.status}: ${response.statusText}`
              );
            }

            const data = await response.arrayBuffer();
            console.log(
              `âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: ${file} (${Math.round(data.byteLength / 1024)}KB)`
            );

            // Blob URLã‚’ä½œæˆ
            const mimeType = file.endsWith('.wasm')
              ? 'application/wasm'
              : file.endsWith('.js')
                ? 'application/javascript'
                : 'application/octet-stream';
            const blob = new Blob([data], { type: mimeType });
            const blobUrl = URL.createObjectURL(blob);

            preloadedUrls.set(file, blobUrl);
            localBlobUrls.push(blobUrl);

            // ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§IndexedDBã«ã‚‚ä¿å­˜ï¼ˆæ¬¡å›ç”¨ï¼‰
            assetManager.saveAsset(file, data).catch(err => {
              console.warn(
                `IndexedDBã¸ã®ä¿å­˜ã«å¤±æ•—ï¼ˆæ¬¡å›ã¯CDNã‹ã‚‰å†å–å¾—ã—ã¾ã™ï¼‰: ${file}`,
                err
              );
            });
          } catch (downloadError) {
            console.error(
              `âŒ CDNã‹ã‚‰ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: ${file}`,
              downloadError
            );
            // æœ€å¾Œã®æ‰‹æ®µã¨ã—ã¦CDN URLã‚’ç›´æ¥ä½¿ç”¨ï¼ˆMediaPipeã«ä»»ã›ã‚‹ï¼‰
            console.warn(
              `âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: MediaPipeã«ç›´æ¥CDNã‹ã‚‰èª­ã¿è¾¼ã¾ã›ã¾ã™`
            );
            preloadedUrls.set(file, cdnUrl);
          }
        }
      } catch (error) {
        console.error(`ã‚¢ã‚»ãƒƒãƒˆæº–å‚™ã‚¨ãƒ©ãƒ¼: ${file}`, error);
        // ã‚¨ãƒ©ãƒ¼æ™‚ã¯CDN URLã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        preloadedUrls.set(
          file,
          `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
        );
      }
    }

    console.log('âœ… MediaPipeã‚¢ã‚»ãƒƒãƒˆã®äº‹å‰æº–å‚™å®Œäº†');
  }

  async function initializeMediaPipe() {
    try {
      faceMesh = new FaceMesh({
        locateFile: (file: string) => {
          // äº‹å‰æº–å‚™ã—ãŸURLã‚’åŒæœŸçš„ã«è¿”ã™
          const url =
            preloadedUrls.get(file) ||
            `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
          console.log(
            `ğŸ“ MediaPipeãƒ•ã‚¡ã‚¤ãƒ«æä¾›: ${file} -> ${url.substring(0, 50)}...`
          );
          return url;
        },
      });

      // Use settings from API configuration
      const mediaPipeSettings = config.mediaPipeConfig;
      faceMesh.setOptions({
        maxNumFaces: mediaPipeSettings.maxDetectedFaces,
        refineLandmarks: mediaPipeSettings.enableRefinedLandmarks,
        minDetectionConfidence: mediaPipeSettings.minDetectionConfidence,
        minTrackingConfidence: mediaPipeSettings.minTrackingConfidence,
        selfieMode: mediaPipeSettings.selfieMode,
        staticImageMode: mediaPipeSettings.staticImageMode,
      });

      faceMesh.onResults(onResults);
      console.log('âœ… FaceMeshè¨­å®šå®Œäº†ã€onResultsã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ç™»éŒ²å®Œäº†');
    } catch (error) {
      console.error('âŒ MediaPipeåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }

  // ã‚­ãƒ£ãƒ³ãƒã‚¹åŒæœŸæ©Ÿèƒ½ã¯å‰Šé™¤

  async function startCamera() {
    // Check initialization readiness
    if (
      !isMediaPipeReady ||
      !isCameraConfigReady ||
      initializationStep !== 'ready'
    ) {
      console.log('â³ ã‚«ãƒ¡ãƒ©ã®æº–å‚™ãŒã¾ã å®Œäº†ã—ã¦ã„ã¾ã›ã‚“');
      return;
    }

    if (!videoElement || !faceMesh) {
      console.log('âŒ å¿…è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
      return;
    }

    if (isStartingCamera) {
      console.log('â³ ã‚«ãƒ¡ãƒ©èµ·å‹•å‡¦ç†ãŒæ—¢ã«å®Ÿè¡Œä¸­ã§ã™');
      return;
    }

    initializationStep = 'camera';
    isStartingCamera = true;
    console.log('ğŸ“· ã‚«ãƒ¡ãƒ©èµ·å‹•ã‚’é–‹å§‹ã—ã¾ã™');
    try {
      // MediaPipe Camera utilsã‚’ä½¿ã‚ãšã«ç‹¬è‡ªã§ã‚«ãƒ¡ãƒ©ã‚’åˆ¶å¾¡
      // ã‚¹ãƒãƒ›å‘ã‘ã«ç¸¦å‘ãã®ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å–å¾—
      const isMobile = /iPhone|iPad|Android/i.test(navigator.userAgent);
      const isPortrait = window.innerHeight > window.innerWidth;

      let constraints: MediaStreamConstraints | undefined;
      let finalStream: MediaStream;

      // ã‚¹ãƒãƒ›ç¸¦å‘ãã®å ´åˆã€è¤‡æ•°ã®è§£åƒåº¦ã‚’è©¦ã™
      if (isMobile && isPortrait) {
        // åˆ©ç”¨å¯èƒ½ãªå…¨è§£åƒåº¦ã‚’å–å¾—ã—ã¦ç¸¦å‘ãã‚’æ¢ã™
        try {
          const devices = await navigator.mediaDevices.enumerateDevices();
          const videoDevices = devices.filter(
            device => device.kind === 'videoinput'
          );
          console.log('ğŸ“± Available video devices:', videoDevices.length);

          // ã¾ãšã¯åˆ¶ç´„ãªã—ã§ã‚«ãƒ¡ãƒ©èƒ½åŠ›ã‚’ç¢ºèª
          const testStream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: 'user' },
          });
          const testTrack = testStream.getVideoTracks()[0];
          const capabilities = testTrack.getCapabilities();
          testStream.getTracks().forEach(track => track.stop());

          console.log('ğŸ“· Camera capabilities:', capabilities);

          // åˆ©ç”¨å¯èƒ½ãªè§£åƒåº¦ã‹ã‚‰ç¸¦å‘ãã‚’å„ªå…ˆçš„ã«é¸æŠ
          const availableResolutions = [];
          if (capabilities.width && capabilities.height) {
            const maxWidth = capabilities.width.max || 1920;
            const maxHeight = capabilities.height.max || 1080;
            console.log(`ğŸ“ Max resolution: ${maxWidth}x${maxHeight}`);

            // ç¸¦å‘ãè§£åƒåº¦ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆ
            if (maxHeight >= maxWidth) {
              // ã™ã§ã«ç¸¦é•·ã®å ´åˆ
              availableResolutions.push({ width: maxWidth, height: maxHeight });
            } else {
              // æ¨ªé•·ã®å ´åˆã€ç¸¦æ¨ªã‚’å…¥ã‚Œæ›¿ãˆã¦ç¸¦å‘ãã«ã™ã‚‹
              availableResolutions.push({ width: maxHeight, height: maxWidth });
              availableResolutions.push({ width: maxWidth, height: maxHeight });
            }
          }
        } catch (e) {
          console.log('âŒ Failed to get capabilities:', e);
        }

        // ç”»é¢ã‚µã‚¤ã‚ºã‹ã‚‰å‹•çš„ã«resolutionPatternsã‚’è¨ˆç®—
        const screenWidth = window.innerWidth;
        const screenHeight = window.innerHeight;
        const screenAspectRatio = screenWidth / screenHeight;

        console.log('ğŸ“± Screen info for resolution calculation:', {
          screenWidth,
          screenHeight,
          screenAspectRatio: screenAspectRatio.toFixed(3),
        });

        // ã‚¹ãƒãƒ›ã‚«ãƒ¡ãƒ©ã«é©ã—ãŸè§£åƒåº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆï¼ˆç¸¦é•·ã§ã‚‚æ¨ªé•·è§£åƒåº¦ã‚’ä½¿ç”¨ï¼‰
        const resolutionPatterns = [
          // é«˜è§£åƒåº¦ï¼ˆæ­£æ–¹å½¢ã«è¿‘ã„ï¼‰
          { width: 1080, height: 1080, aspectRatio: 1.0 },
          { width: 960, height: 1280, aspectRatio: 0.75 }, // 3:4
          { width: 720, height: 960, aspectRatio: 0.75 }, // 3:4
          // 4:3ï¼ˆã‚«ãƒ¡ãƒ©ã®æ¨™æº–ï¼‰
          { width: 960, height: 720, aspectRatio: 4 / 3 },
          { width: 640, height: 480, aspectRatio: 4 / 3 },
          // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨
          { width: 480, height: 640, aspectRatio: 0.75 },
          { width: 360, height: 480, aspectRatio: 0.75 },
        ];

        console.log('ğŸ“± Generated resolution patterns:', resolutionPatterns);

        let stream = null;
        let successfulPattern = null;

        for (const pattern of resolutionPatterns) {
          try {
            constraints = {
              video: {
                facingMode: 'user',
                width: { ideal: pattern.width },
                height: { ideal: pattern.height },
                aspectRatio: { ideal: pattern.aspectRatio },
                // exactã‚„min/maxã‚’å‰Šé™¤ã—ã¦åˆ¶ç´„ã‚’ç·©å’Œ
              },
              audio: false,
            };

            console.log(
              `ğŸ“± Trying resolution: ${pattern.width}x${pattern.height}`
            );
            stream = await navigator.mediaDevices.getUserMedia(constraints);
            successfulPattern = pattern;
            console.log(
              `âœ… Successfully got stream with: ${pattern.width}x${pattern.height}`
            );
            break;
          } catch (e) {
            console.log(
              `âŒ Failed with ${pattern.width}x${pattern.height}:`,
              (e as Error).message
            );
          }
        }

        if (!stream) {
          // ç‰¹å®šã®ãƒ‡ãƒã‚¤ã‚¹IDã‚’æŒ‡å®šã—ã¦è©¦ã™
          const devices = await navigator.mediaDevices.enumerateDevices();
          const videoDevices = devices.filter(
            device => device.kind === 'videoinput'
          );
          console.log(
            'ğŸ“± Trying specific camera devices:',
            videoDevices.length
          );

          for (const device of videoDevices) {
            console.log(`ğŸ“· Trying device: ${device.label || device.deviceId}`);
            for (const pattern of resolutionPatterns) {
              try {
                constraints = {
                  video: {
                    deviceId: { exact: device.deviceId },
                    width: { ideal: pattern.width },
                    height: { ideal: pattern.height },
                    aspectRatio: { ideal: pattern.aspectRatio },
                  },
                  audio: false,
                };

                stream = await navigator.mediaDevices.getUserMedia(constraints);
                successfulPattern = pattern;
                console.log(
                  `âœ… Success with device ${device.label} at ${pattern.width}x${pattern.height}`
                );
                break;
              } catch (e) {
                // æ¬¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™
              }
            }
            if (stream) break;
          }
        }

        if (!stream) {
          // æœ€å¾Œã®æ‰‹æ®µï¼šæ®µéšçš„ã«åˆ¶ç´„ã‚’ç·©å’Œ
          console.log(
            'ğŸ“± ã™ã¹ã¦ã®è§£åƒåº¦ã§å¤±æ•—ã—ã¾ã—ãŸã€‚åˆ¶ç´„ã‚’ç·©å’Œã—ã¦ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™'
          );

          const fallbackPatterns = [
            // æ®µéš1: ãƒ•ãƒ­ãƒ³ãƒˆã‚«ãƒ¡ãƒ©ã®ã¿æŒ‡å®š
            { video: { facingMode: 'user' }, audio: false },
            // æ®µéš2: ä»»æ„ã®ã‚«ãƒ¡ãƒ©
            { video: true, audio: false },
            // æ®µéš3: æœ€å°åˆ¶ç´„
            { video: {}, audio: false },
          ];

          for (const fallback of fallbackPatterns) {
            try {
              console.log('ğŸ“± ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ¶ç´„ã§ãƒªãƒˆãƒ©ã‚¤ä¸­...');
              stream = await navigator.mediaDevices.getUserMedia(fallback);
              console.log('âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ¶ç´„ã§æˆåŠŸ');
              break;
            } catch (e) {
              console.log('âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ¶ç´„ã‚‚å¤±æ•—');
              continue;
            }
          }

          if (!stream) {
            throw new Error('ã™ã¹ã¦ã®ã‚«ãƒ¡ãƒ©åˆ¶ç´„ã§å¤±æ•—ã—ã¾ã—ãŸ');
          }
        }

        finalStream = stream;
      } else if (isMobile && !isPortrait) {
        // ã‚¹ãƒãƒ›æ¨ªå‘ãã®å ´åˆ
        try {
          constraints = {
            video: {
              facingMode: 'user',
              width: { min: 640, ideal: 1280, max: 1920 },
              height: { min: 480, ideal: 720, max: 1080 },
              aspectRatio: { ideal: 1.777 }, // 16:9 = 1.777
            },
            audio: false,
          };
          finalStream = await navigator.mediaDevices.getUserMedia(constraints);
        } catch (e) {
          console.log(
            'ğŸ“± æ¨ªå‘ãã®åˆ¶ç´„ãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™'
          );
          // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚ˆã‚Šç·©ã„åˆ¶ç´„
          finalStream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: 'user' },
            audio: false,
          });
        }
      } else {
        // PCã®å ´åˆ
        try {
          constraints = {
            video: {
              facingMode: 'user',
              width: { ideal: 1280 },
              height: { ideal: 720 },
              aspectRatio: { ideal: 1.777 },
            },
            audio: false,
          };
          finalStream = await navigator.mediaDevices.getUserMedia(constraints);
        } catch (e) {
          console.log('ğŸ’» PCã®åˆ¶ç´„ãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™');
          // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚ˆã‚Šç·©ã„åˆ¶ç´„
          finalStream = await navigator.mediaDevices.getUserMedia({
            video: true,
            audio: false,
          });
        }
      }

      console.log(
        'ğŸ“± Final constraints used:',
        typeof constraints !== 'undefined' ? constraints : 'No constraints set'
      );

      const stream = finalStream;

      // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®å®Ÿéš›ã®è¨­å®šã‚’ç¢ºèª
      const videoTrack = stream.getVideoTracks()[0];
      const settings = videoTrack.getSettings();
      console.log('ğŸ“· Actual camera settings:', {
        width: settings.width,
        height: settings.height,
        aspectRatio: settings.aspectRatio,
        facingMode: settings.facingMode,
      });

      videoElement.srcObject = stream;
      await videoElement.play();

      // ãƒ“ãƒ‡ã‚ªã®å®Ÿéš›ã®ã‚µã‚¤ã‚ºã‚’ç¢ºèª
      console.log('ğŸ“º Video element dimensions:', {
        videoWidth: videoElement.videoWidth,
        videoHeight: videoElement.videoHeight,
        clientWidth: videoElement.clientWidth,
        clientHeight: videoElement.clientHeight,
      });

      // MediaPipeã«ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é€ã‚‹å‡¦ç†ã‚’ç‹¬è‡ªã«å®Ÿè£…
      let animationId: number;
      let frameCount = 0;
      const sendFrame = async () => {
        if (faceMesh && videoElement && videoElement.readyState >= 2) {
          try {
            await faceMesh.send({ image: videoElement });
            frameCount++;
            // æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ é€ä¿¡ã‚’ãƒ­ã‚°
            if (frameCount === 1) {
              console.log('âœ… æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’MediaPipeã«é€ä¿¡æˆåŠŸ');
            }
          } catch (error) {
            console.error('âŒ MediaPipeãƒ•ãƒ¬ãƒ¼ãƒ é€ä¿¡ã‚¨ãƒ©ãƒ¼:', error);
            console.error('ã‚¨ãƒ©ãƒ¼è©³ç´°:', {
              faceMesh: !!faceMesh,
              videoElement: !!videoElement,
              readyState: videoElement?.readyState,
              error: error,
            });
          }
        }
        animationId = requestAnimationFrame(sendFrame);
      };

      // ãƒ•ãƒ¬ãƒ¼ãƒ é€ä¿¡ã‚’é–‹å§‹
      console.log('ğŸ¬ ãƒ•ãƒ¬ãƒ¼ãƒ é€ä¿¡ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ã—ã¾ã™');
      sendFrame();

      // ã‚«ãƒ¡ãƒ©åœæ­¢æ™‚ã«ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ãŸã‚ã«ä¿å­˜
      camera = {
        stop: () => {
          if (animationId) {
            cancelAnimationFrame(animationId);
          }
          if (stream) {
            stream.getTracks().forEach(track => track.stop());
          }
        },
      };

      // Wait for video to be ready
      if (videoElement.readyState < 2) {
        await new Promise(resolve => {
          const checkReady = () => {
            if (videoElement.readyState >= 2) {
              resolve(true);
            } else {
              setTimeout(checkReady, 50);
            }
          };
          checkReady();
        });
      }

      // Reset detection state when camera starts
      faceDetected = false;
      faceDetectionCount = 0;
      faceDetectionStartTime = null;
      stablePosition = false;
      stableStartTime = null;
      progress = 0;

      initializationStep = 'processing';
      console.log('ğŸ“· ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®å–å¾—ãŒå®Œäº†ã—ã¾ã—ãŸ');
      console.log('ğŸ”„ MediaPipeã®å®Œå…¨åˆæœŸåŒ–ã‚’å¾…æ©Ÿä¸­...');

      // Don't dispatch cameraStarted yet - wait for MediaPipe to be fully ready
      // dispatch('cameraStarted'); // Moved to onResults after first frame processing
    } catch (error) {
      initializationStep = 'error';
      console.error('âŒ ã‚«ãƒ¡ãƒ©èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ');
      dispatch('error', {
        message:
          'ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ã€‚',
      });
    } finally {
      isStartingCamera = false;
    }
  }

  function onResults(results: any) {
    // æœ€åˆã®å‘¼ã³å‡ºã—ã‚’ãƒ­ã‚°
    if (!hasProcessedFirstFrame) {
      console.log('ğŸ¯ onResults ãŒåˆã‚ã¦å‘¼ã°ã‚Œã¾ã—ãŸ');
    }

    if (!canvasCtx && canvasElement) {
      canvasCtx = canvasElement.getContext('2d')!;
    }

    if (!canvasCtx || !canvasElement) {
      console.warn('âš ï¸ canvasCtx ã¾ãŸã¯ canvasElement ãŒæº–å‚™ã§ãã¦ã„ã¾ã›ã‚“');
      return;
    }

    // Check if this is the first successful frame processing
    if (!hasProcessedFirstFrame && !isMediaPipeFullyInitialized) {
      hasProcessedFirstFrame = true;
      isMediaPipeFullyInitialized = true;
      initializationStep = 'ready';
      console.log('âœ… MediaPipeã®åˆæœŸåŒ–ãŒå®Œå…¨ã«å®Œäº†ã—ã¾ã—ãŸ');
      console.log('ğŸ‰ ã‚«ãƒ¡ãƒ©ãŒä½¿ç”¨å¯èƒ½ã«ãªã‚Šã¾ã—ãŸ');
      dispatch('cameraStarted');
    }

    // ãƒ“ãƒ‡ã‚ªã®å®Ÿéš›ã®ã‚µã‚¤ã‚ºã‚’å–å¾—
    const videoWidth =
      results.image.width ||
      results.image.videoWidth ||
      videoElement?.videoWidth ||
      720;
    const videoHeight =
      results.image.height ||
      results.image.videoHeight ||
      videoElement?.videoHeight ||
      1280;

    // ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚ºã‚’ãƒ“ãƒ‡ã‚ªã®ã‚µã‚¤ã‚ºã«å®Œå…¨ã«ä¸€è‡´ã•ã›ã‚‹
    if (
      canvasElement.width !== videoWidth ||
      canvasElement.height !== videoHeight
    ) {
      canvasElement.width = videoWidth;
      canvasElement.height = videoHeight;
      console.log('ğŸ“ Canvas resized to match video:', {
        width: videoWidth,
        height: videoHeight,
      });
    }

    // Clear canvas
    canvasCtx.save();
    canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

    // Save current video dimensions for coordinate transformation
    currentVideoWidth = videoWidth;
    currentVideoHeight = videoHeight;

    // ãƒ“ãƒ‡ã‚ªã‚’ãã®ã¾ã¾ã®ã‚µã‚¤ã‚ºã§æç”»ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãªã—ï¼‰
    canvasCtx.drawImage(results.image, 0, 0, videoWidth, videoHeight);

    // Debug: Log drawing dimensions (only occasionally to avoid spam)
    if (Math.random() < 0.01) {
      // 1% chance to log
    }

    const hasFace =
      results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0;
    // MediaPipeçµæœã®ãƒ­ã‚°ã¯å‰Šé™¤ï¼ˆå¿…è¦æ™‚ã®ã¿æœ‰åŠ¹åŒ–ï¼‰
    // console.log('ğŸ“¸ MediaPipe results:', { hasFace, faceCount: results.multiFaceLandmarks?.length || 0 });

    if (hasFace) {
      const landmarks = results.multiFaceLandmarks[0];
      faceLandmarks = landmarks;

      // Calculate pose
      const pose = calculatePose(landmarks);
      // å§¿å‹¢è¨ˆç®—ã®ãƒ­ã‚°ã¯å‰Šé™¤ï¼ˆå¿…è¦æ™‚ã®ã¿æœ‰åŠ¹åŒ–ï¼‰
      // console.log('ğŸ“ Calculated pose:', pose);

      // Analyze expression (only if enabled)
      if (enableExpressionDetection === true) {
        currentExpression = expressionAnalyzer.analyzeExpression(landmarks);
      } else {
        currentExpression = null;
      }

      updateStability(pose);

      if (showMesh) {
        drawFaceMesh(landmarks);
      }

      // Face detection stability
      faceDetectionCount++;

      if (!faceDetected && faceDetectionCount >= FACE_DETECTION_THRESHOLD) {
        faceDetected = true;

        if (currentMode !== CaptureMode?.CAMERA_STARTUP) {
          faceDetectionStartTime = performance.now();

          // ãƒ‡ã‚¶ã‚¤ãƒ³ã«ãªã„ãŸã‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã—ãªã„
        }
      }

      // Check auto capture (exclude preview modes)
      if (
        currentMode !== CaptureMode?.CAMERA_STARTUP &&
        currentMode !== CaptureMode?.PREVIEW_BEFORE &&
        currentMode !== CaptureMode?.PREVIEW_AFTER
      ) {
        checkAutoCapture();
      }

      // çµ±åˆã‚¬ã‚¤ãƒ€ãƒ³ã‚¹åˆ¤å®šï¼ˆå§¿å‹¢å„ªå…ˆã€è¡¨æƒ…ã¯å§¿å‹¢OKã®å ´åˆã®ã¿ï¼‰
      const guidanceInfo = determineGuidance(
        pose,
        currentExpression,
        landmarks
      );

      dispatch('faceDetected', {
        landmarks,
        pose,
        expression: currentExpression, // è¡¨æƒ…ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        stable: stablePosition,
        progress,
        guidance: guidanceInfo,
      });
    } else {
      // No face detected
      // console.log('âŒ No face detected'); // ãƒ­ã‚°å‰Šé™¤
      handleNoFaceDetected();
    }

    drawUIOverlays();
    canvasCtx.restore();
  }

  function drawFaceMesh(landmarks: any) {
    if (!canvasCtx) return;

    drawConnectors(canvasCtx, landmarks, FACEMESH_TESSELATION, {
      color: '#C0C0C070',
      lineWidth: 1,
    });
    drawConnectors(canvasCtx, landmarks, FACEMESH_RIGHT_EYE, {
      color: '#FF3030',
    });
    drawConnectors(canvasCtx, landmarks, FACEMESH_LEFT_EYE, {
      color: '#30FF30',
    });
    drawConnectors(canvasCtx, landmarks, FACEMESH_FACE_OVAL, {
      color: '#E0E0E0',
    });
    drawConnectors(canvasCtx, landmarks, FACEMESH_LIPS, {
      color: '#E0E0E0',
    });
  }

  function handleNoFaceDetected() {
    faceDetectionCount = 0;

    if (faceDetected) {
      faceDetected = false;
      faceDetectionStartTime = null;
    }

    stablePosition = false;
    stableStartTime = null;
    progress = 0;

    // Clear pose guidance in CAMERA_STARTUP mode
    if (currentMode === CaptureMode?.CAMERA_STARTUP) {
      showPoseGuidance = false;
      poseGuidanceMessage = '';
    }

    // ãƒ‡ã‚¶ã‚¤ãƒ³ã«ãªã„ãŸã‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯é€ä¿¡ã—ãªã„

    dispatch('faceDetected', {
      landmarks: null,
      pose: null,
      stable: false,
      progress: 0,
    });

    showPoseGuidance = false;
    lastGuidanceMessage = '';
  }

  function calculateFaceSize(landmarks: any): number {
    try {
      // é¡”ã®å¢ƒç•Œã‚’è¨ˆç®—
      let minX = 1,
        maxX = 0,
        minY = 1,
        maxY = 0;

      // é¡”ã®è¼ªéƒ­ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦å¢ƒç•Œã‚’è¨ˆç®—
      const faceContourIndices = [
        10, 151, 9, 8, 168, 6, 197, 195, 5, 4, 1, 19, 94, 125, 142, 36, 205,
        206, 207, 213, 192, 147, 187, 207, 206, 205, 36, 142, 125, 94, 19, 1, 4,
        5, 195, 197, 6, 168, 8, 9, 151, 10,
      ];

      for (const index of faceContourIndices) {
        if (landmarks[index]) {
          minX = Math.min(minX, landmarks[index].x);
          maxX = Math.max(maxX, landmarks[index].x);
          minY = Math.min(minY, landmarks[index].y);
          maxY = Math.max(maxY, landmarks[index].y);
        }
      }

      // é¡”ã®ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ï¼ˆç”»åƒã«å¯¾ã™ã‚‹ç›¸å¯¾ã‚µã‚¤ã‚ºï¼‰
      const faceWidth = maxX - minX;
      const faceHeight = maxY - minY;
      const faceSize = Math.sqrt(
        faceWidth * faceWidth + faceHeight * faceHeight
      );

      return faceSize;
    } catch (error) {
      return 0;
    }
  }

  function calculatePose(landmarks: any) {
    // PHPç‰ˆã¨å®Œå…¨ã«åŒã˜å§¿å‹¢è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
    try {
      // ç‰¹å¾´ç‚¹ã®å–å¾—ï¼ˆPHPã¨åŒã˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰
      const nose = landmarks[1];
      const leftEye = landmarks[33];
      const rightEye = landmarks[263];
      const leftMouth = landmarks[61];
      const rightMouth = landmarks[291];

      if (!nose || !leftEye || !rightEye || !leftMouth || !rightMouth) {
        throw new Error('Required landmarks not found');
      }

      // ãƒ­ãƒ¼ãƒ«ï¼ˆZè»¸å›è»¢ï¼‰- ç›®ã®å‚¾ã - ãƒŸãƒ©ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œ
      const eyeDiffY = rightEye.y - leftEye.y;
      const eyeDiffX = rightEye.x - leftEye.x;
      const roll = (-Math.atan2(eyeDiffY, eyeDiffX) * 180) / Math.PI;

      // ãƒ”ãƒƒãƒï¼ˆXè»¸å›è»¢ï¼‰- ç¸¦æ–¹å‘ã®å‚¾ã - ä¿®æ­£ç‰ˆ
      const eyeCenter = {
        y: (leftEye.y + rightEye.y) / 2,
        z: (leftEye.z + rightEye.z) / 2,
      };

      // é¼»ã¨ç›®ã®ä¸­å¿ƒã®ä½ç½®é–¢ä¿‚
      const eyeNoseY = eyeCenter.y - nose.y;
      const eyeNoseZ = eyeCenter.z - nose.z;

      // è§’åº¦è¨ˆç®— - ç¬¦å·ã¨å¼•æ•°ã‚’èª¿æ•´
      let rawPitch = (-Math.atan2(eyeNoseZ, eyeNoseY) * 180) / Math.PI;

      // 180åº¦å•é¡Œã®è§£æ±º
      if (rawPitch > 90) {
        rawPitch = rawPitch - 180;
      } else if (rawPitch < -90) {
        rawPitch = rawPitch + 180;
      }

      // æœ€çµ‚çš„ãªãƒ”ãƒƒãƒå€¤ï¼ˆãƒ‡ãƒã‚¤ã‚¹åˆ¥ã‚ªãƒ•ã‚»ãƒƒãƒˆ - APIè¨­å®šä½¿ç”¨ï¼‰
      const pitchCalibration = config.poseCalculationConfig.pitchCalibration;
      const deviceAdjustment = getDevicePitchAdjustment(pitchCalibration);
      const pitch =
        rawPitch + pitchCalibration.baseOffsetDegrees + deviceAdjustment;

      // ãƒ¨ãƒ¼ï¼ˆYè»¸å›è»¢ï¼‰- æ¨ªæ–¹å‘ã®å‘ãï¼ˆAPIè¨­å®šä½¿ç”¨ï¼‰
      const eyeMidPoint = {
        x: (leftEye.x + rightEye.x) / 2,
      };
      const noseMidOffset = eyeMidPoint.x - nose.x;
      const yaw = noseMidOffset * config.poseCalculationConfig.yawSensitivity;

      // é¡”ã®ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
      const faceSize = calculateFaceSize(landmarks);

      // è·é›¢ã¨å“è³ªã®è¨ˆç®—ï¼ˆAPIè¨­å®šä½¿ç”¨ï¼‰
      const qualityConfig = config.poseCalculationConfig.qualityCalculation;
      const eyeDistance = Math.sqrt(eyeDiffX * eyeDiffX + eyeDiffY * eyeDiffY);
      const distance = Math.max(
        qualityConfig.distanceRange.min,
        Math.min(qualityConfig.distanceRange.max, 1.0 / eyeDistance)
      );
      const quality = Math.max(
        0.0,
        Math.min(1.0, faceSize * qualityConfig.faceSizeMultiplier)
      );

      const result = {
        roll: Math.round(roll * 10) / 10,
        pitch: Math.round(pitch * 10) / 10,
        yaw: Math.round(yaw * 10) / 10,
        distance: Math.round(distance * 100) / 100,
        quality: Math.round(quality * 100) / 100,
        faceSize: Math.round(faceSize * 1000) / 1000,
      };

      return result;
    } catch (error) {
      return {
        roll: 0,
        pitch: 0,
        yaw: 0,
        distance: 1.0,
        quality: 0.0,
        faceSize: 0.0,
      };
    }
  }

  function updateStability(pose: any) {
    const now = performance.now();

    // PHPç‰ˆã¨åŒã˜å³ã—ã„æ¡ä»¶
    const isGoodPose =
      Math.abs(pose.roll) < THRESHOLDS.roll &&
      Math.abs(pose.pitch) < THRESHOLDS.pitch &&
      Math.abs(pose.yaw) < THRESHOLDS.yaw &&
      pose.quality >= MIN_FACE_QUALITY &&
      pose.faceSize >= MIN_FACE_SIZE;

    // è¡¨æƒ…ãƒã‚§ãƒƒã‚¯ - è¡¨æƒ…ã«å•é¡ŒãŒã‚ã‚‹å ´åˆã¯å®‰å®šçŠ¶æ…‹ã«ã—ãªã„
    const isGoodExpression =
      enableExpressionDetection === true
        ? currentExpression
          ? expressionAnalyzer.isExpressionAcceptable(currentExpression)
          : true
        : true; // Expression detection disabled, assume OK

    // å§¿å‹¢ã¨è¡¨æƒ…ã®ä¸¡æ–¹ãŒè‰¯å¥½ãªå ´åˆã®ã¿å®‰å®šçŠ¶æ…‹ã¨ã™ã‚‹
    const isStable = isGoodPose && isGoodExpression;

    // å§¿å‹¢å®‰å®šæ€§ãƒã‚§ãƒƒã‚¯ã®ãƒ­ã‚°ã¯å‰Šé™¤ï¼ˆå¿…è¦æ™‚ã®ã¿æœ‰åŠ¹åŒ–ï¼‰
    // console.log('ğŸ¯ Pose stability check:', { roll: pose.roll.toFixed(1), pitch: pose.pitch.toFixed(1), yaw: pose.yaw.toFixed(1), isGoodPose, isGoodExpression, isStable, progress: progress.toFixed(1) });

    if (isStable) {
      if (!stablePosition) {
        stablePosition = true;
        stableStartTime = now;
        showPoseGuidance = true;
        poseGuidanceMessage = 'è‰¯ã„å§¿å‹¢ã§ã™ï¼ä¿æŒã—ã¦ãã ã•ã„';
        poseGuidanceType = 'success';

        // æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯2ç§’å¾Œã«éè¡¨ç¤ºã«ã™ã‚‹
        setTimeout(() => {
          if (stablePosition) {
            showPoseGuidance = false;
          }
        }, 2000);
      }

      if (stableStartTime) {
        const elapsed = (now - stableStartTime) / 1000;
        // ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’å§¿å‹¢å®‰å®šå¾Œã®è‡ªå‹•æ’®å½±å¾…æ©Ÿæ™‚é–“ï¼ˆFACE_DETECTION_DELAYï¼‰ã«åˆã‚ã›ã‚‹
        progress = Math.min((elapsed / FACE_DETECTION_DELAY) * 100, 100);

        if (progress >= 100) {
        }
      }
    } else {
      // å§¿å‹¢ã¾ãŸã¯è¡¨æƒ…ã«å•é¡ŒãŒã‚ã‚‹å ´åˆã¯ãƒªã‚»ãƒƒãƒˆ
      if (stablePosition) {
      }
      stablePosition = false;
      stableStartTime = null;
      progress = 0;

      // Guidance messages - å§¿å‹¢ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã®ã¿æ›´æ–°ï¼ˆè¡¨æƒ…ã¯çµ±åˆã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã§å‡¦ç†ï¼‰
      if (now - lastGuidanceUpdate > GUIDANCE_UPDATE_INTERVAL && !isGoodPose) {
        updatePoseGuidance(pose);
        lastGuidanceUpdate = now;
      }
    }
  }

  // å§¿å‹¢ã«åŸºã¥ã„ã¦ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆEnumãƒ™ãƒ¼ã‚¹ï¼‰
  function getPoseGuidanceData(pose: any): PoseGuidanceData | null {
    if (!pose) return null;

    // å„ªå…ˆé †ä½ã«å¾“ã£ã¦åˆ¤å®šï¼ˆPHPç‰ˆã¨åŒã˜é †ç•ªï¼‰
    if (pose.faceSize < MIN_FACE_SIZE) {
      return POSE_GUIDANCE_MAP.tooFar;
    } else if (pose.quality < MIN_FACE_QUALITY) {
      return POSE_GUIDANCE_MAP.lowQuality;
    } else if (Math.abs(pose.roll) >= THRESHOLDS.roll) {
      return pose.roll > 0
        ? POSE_GUIDANCE_MAP.rollPositive
        : POSE_GUIDANCE_MAP.rollNegative;
    } else if (Math.abs(pose.pitch) >= THRESHOLDS.pitch) {
      return pose.pitch > 0
        ? POSE_GUIDANCE_MAP.pitchPositive
        : POSE_GUIDANCE_MAP.pitchNegative;
    } else if (Math.abs(pose.yaw) >= THRESHOLDS.yaw) {
      return pose.yaw > 0
        ? POSE_GUIDANCE_MAP.yawPositive
        : POSE_GUIDANCE_MAP.yawNegative;
    } else {
      return POSE_GUIDANCE_MAP.perfect;
    }
  }

  function getGuidanceDirection(pose: any): PoseGuidanceDirection | null {
    const guidanceData = getPoseGuidanceData(pose);
    return guidanceData?.direction || null;
  }

  // PHPã¨åŒã˜é¼»ã®ä½ç½®è¨ˆç®—ï¼ˆå®Œå…¨ç§»æ¤ç‰ˆï¼‰
  function getNosePosition(landmarks: any) {
    if (
      !landmarks ||
      !canvasElement ||
      currentVideoWidth === 0 ||
      currentVideoHeight === 0
    ) {
      // Debug: Log why getNosePosition is returning null
      if (Math.random() < 0.1) {
        // 10% chance to avoid spam
      }
      return null;
    }

    // é¼»ã®å…ˆç«¯ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹1ï¼‰
    const nose = landmarks[1];
    if (!nose) return null;

    // onResultsé–¢æ•°ã¨åŒã˜ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”è¨ˆç®—ã‚’ä½¿ç”¨
    const videoWidth = currentVideoWidth;
    const videoHeight = currentVideoHeight;
    const canvasWidth = canvasElement.width;
    const canvasHeight = canvasElement.height;

    const videoAspect = videoWidth / videoHeight;
    const canvasAspect = canvasWidth / canvasHeight;

    let drawWidth, drawHeight, drawX, drawY;

    if (videoAspect > canvasAspect) {
      // Video is wider - fit to canvas height
      drawHeight = canvasHeight;
      drawWidth = drawHeight * videoAspect;
      drawX = (canvasWidth - drawWidth) / 2;
      drawY = 0;
    } else {
      // Video is taller - fit to canvas width
      drawWidth = canvasWidth;
      drawHeight = drawWidth / videoAspect;
      drawX = 0;
      drawY = (canvasHeight - drawHeight) / 2;
    }

    // å®Ÿéš›ã®æç”»é ˜åŸŸå†…ã§ã®åº§æ¨™è¨ˆç®—
    const noseX = (1 - nose.x) * drawWidth + drawX;
    const noseY = nose.y * drawHeight + drawY;

    // è¡¨ç¤ºã‚µã‚¤ã‚ºã«åˆã‚ã›ã¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    const canvasRect = canvasElement.getBoundingClientRect();
    const scaleX = canvasRect.width / canvasElement.width;
    const scaleY = canvasRect.height / canvasElement.height;

    const displayX = noseX * scaleX;
    const displayY = noseY * scaleY;

    // Debug: Log successful nose position calculation
    if (Math.random() < 0.05) {
      // 5% chance to avoid spam
    }

    return { x: displayX, y: displayY };
  }

  function updatePoseGuidance(pose: any) {
    // Don't show pose guidance in CAMERA_STARTUP mode
    if (currentMode === CaptureMode?.CAMERA_STARTUP) {
      return;
    }

    // ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆEnumãƒ™ãƒ¼ã‚¹ï¼‰
    const guidanceData = getPoseGuidanceData(pose);

    if (!guidanceData) return;

    const { message, type } = guidanceData;

    if (message) {
      poseGuidanceMessage = message;
      poseGuidanceType = type;
      showPoseGuidance = true;
      lastGuidanceMessage = message;

      // å§¿å‹¢ãŒæ‚ªã„é–“ã¯ç¶™ç¶šçš„ã«è¡¨ç¤ºï¼ˆåŒã˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã‚‚ç¶™ç¶šè¡¨ç¤ºï¼‰
    }
  }

  // PHPã¨åŒã˜ãƒ”ãƒã‚­ã‚ªæ£’ï¼ˆãƒ”ãƒ³ã‚¯è»¸ï¼‰æç”»æ©Ÿèƒ½
  function drawPoseAxes(landmarks: any) {
    if (!canvasCtx || !canvasElement) return;

    // ç¾åœ¨ã®å§¿å‹¢ã‚’è¨ˆç®—
    const pose = calculatePose(landmarks);

    // é¡åƒè¡¨ç¤ºã«å¯¾å¿œã™ã‚‹ãŸã‚ã®å¤‰æ›
    canvasCtx.scale(-1, 1);
    canvasCtx.translate(-canvasElement.width, 0);

    const nose = landmarks[1];
    const scale = 0.2; // è»¸ã®é•·ã•

    // åº§æ¨™è»¸ã®æç”»ï¼ˆé¼»ã‹ã‚‰ä¼¸ã³ã‚‹ãƒ”ãƒ³ã‚¯è»¸ï¼‰
    // ãƒŸãƒ©ãƒ¼ãƒªãƒ³ã‚°æ™‚ã®åº§æ¨™ã«å¤‰æ›
    const noseX = (1 - nose.x) * canvasElement.width;
    const noseY = nose.y * canvasElement.height;

    // Zè»¸ï¼ˆãƒ”ãƒ³ã‚¯ï¼‰- ãƒ¨ãƒ¼ï¼ˆé¡”ã®å‘ãï¼‰ã«å¿œã˜ã¦æ–¹å‘ãŒå¤‰ã‚ã‚‹
    const zAxisX =
      noseX +
      Math.sin((pose.yaw * Math.PI) / 180) * scale * canvasElement.width;

    // å††æŸ±ã®æç”»ï¼ˆZè»¸ï¼‰
    const cylinderWidth = 12; // å††æŸ±ã®å¹…

    // ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§å††æŸ±åŠ¹æœã‚’ä½œæˆ
    const gradient = canvasCtx.createLinearGradient(
      noseX,
      noseY,
      zAxisX,
      noseY
    );
    gradient.addColorStop(0, '#E05179'); // ãƒ”ãƒ³ã‚¯è‰²ï¼ˆå§‹ç‚¹ï¼‰
    gradient.addColorStop(1, 'rgba(224, 81, 121, 0.8)'); // æ˜ã‚‹ã„ãƒ”ãƒ³ã‚¯è‰²ï¼ˆçµ‚ç‚¹ï¼‰

    // å††æŸ±ã®æœ¬ä½“ã‚’æç”»
    canvasCtx.beginPath();
    canvasCtx.moveTo(noseX, noseY - cylinderWidth / 2);
    canvasCtx.lineTo(zAxisX, noseY - cylinderWidth / 2);
    canvasCtx.lineTo(zAxisX, noseY + cylinderWidth / 2);
    canvasCtx.lineTo(noseX, noseY + cylinderWidth / 2);
    canvasCtx.closePath();
    canvasCtx.fillStyle = gradient;
    canvasCtx.fill();

    // çµ‚ç‚¹ã®å††ã‚’æç”»
    canvasCtx.beginPath();
    canvasCtx.arc(zAxisX, noseY, cylinderWidth / 2, 0, Math.PI * 2);
    canvasCtx.fillStyle = 'rgba(224, 81, 121, 0.8)';
    canvasCtx.fill();

    // å§‹ç‚¹ã®å††ã‚’æç”»
    canvasCtx.beginPath();
    canvasCtx.arc(noseX, noseY, cylinderWidth / 2, 0, Math.PI * 2);
    canvasCtx.fillStyle = '#E05179';
    canvasCtx.fill();
  }

  function checkAutoCapture() {
    if (!faceDetected || !stableStartTime) return;

    // å§¿å‹¢ãŒå®‰å®šã—ã¦ã‹ã‚‰ã®çµŒéæ™‚é–“ã‚’è¨ˆç®—
    const elapsed = (performance.now() - stableStartTime) / 1000;

    // è¡¨æƒ…ãƒã‚§ãƒƒã‚¯ - è¡¨æƒ…ã«å•é¡ŒãŒã‚ã‚‹å ´åˆã¯æ’®å½±ã—ãªã„
    const expressionOk =
      enableExpressionDetection === true
        ? currentExpression
          ? expressionAnalyzer.isExpressionAcceptable(currentExpression)
          : true
        : true; // Expression detection disabled, assume OK

    // å§¿å‹¢ãŒå®‰å®šã—ã¦ã‹ã‚‰3ç§’çµŒé + è¡¨æƒ…ã‚‚è‰¯å¥½ãªå ´åˆã«æ’®å½±
    if (
      elapsed >= FACE_DETECTION_DELAY &&
      stablePosition &&
      progress >= 100 &&
      expressionOk
    ) {
      dispatch('autoCapture', { landmarks: faceLandmarks });

      // Reset detection to prevent multiple captures
      faceDetectionStartTime = null;
      faceDetected = false;
      stablePosition = false;
      stableStartTime = null;
      progress = 0;
    }
  }

  function drawUIOverlays() {
    if (!canvasCtx || !canvasElement) return;

    // Save the current transformation matrix
    canvasCtx.save();

    // ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®ã¿æç”»ï¼ˆç™½ã„å††ã¯CSSã§è¡¨ç¤ºï¼‰
    if (
      currentMode !== CaptureMode?.CAMERA_STARTUP &&
      faceDetected &&
      stablePosition &&
      progress > 0
    ) {
      const centerX = canvasElement.width / 2;
      const centerY = canvasElement.height / 2;
      // CSS ã®ãƒã‚¹ã‚¯å††ã¨åŒã˜ã‚µã‚¤ã‚ºã«åˆã‚ã›ã‚‹ï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–å¯¾å¿œï¼‰
      const circleSize = Math.min(300, window.innerWidth * 0.5);
      const radius = circleSize / 2 - 10; // ãƒã‚¹ã‚¯å††ã®å†…å´ã«ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æç”»

      const progressAngle = (progress / 100) * 2 * Math.PI - Math.PI / 2;

      canvasCtx.beginPath();
      canvasCtx.arc(centerX, centerY, radius, -Math.PI / 2, progressAngle);
      canvasCtx.strokeStyle = '#00BEB9';
      canvasCtx.lineWidth = 47;
      canvasCtx.stroke();
    }

    // ãƒ”ãƒã‚­ã‚ªæ£’ï¼ˆãƒ”ãƒ³ã‚¯è»¸ï¼‰ã®æç”» - PHPã¨åŒã˜å®Ÿè£…
    if (faceLandmarks && faceDetected) {
      drawPoseAxes(faceLandmarks);
    }

    // Restore the transformation matrix
    canvasCtx.restore();
  }

  function cleanup() {
    // Stop camera but don't destroy faceMesh (for reuse)
    if (camera) {
      camera.stop();
      camera = null;
    }

    // Stop video stream
    if (videoElement && videoElement.srcObject) {
      const stream = videoElement.srcObject as MediaStream;
      stream.getTracks().forEach(track => {
        track.stop();
      });
      videoElement.srcObject = null;
    }

    // Reset detection state
    faceDetected = false;
    faceDetectionCount = 0;
    faceDetectionStartTime = null;
    stablePosition = false;
    stableStartTime = null;
    progress = 0;
    isStartingCamera = false;
  }

  // Complete cleanup function for component destruction
  function completeCleanup() {
    cleanup();

    if (faceMesh) {
      faceMesh.close();
      faceMesh = null;
    }
  }

  // Export cleanup functions for external use
  export { cleanup, completeCleanup };

  // Export function to get current face landmarks
  export function getCurrentFaceLandmarks() {
    return faceLandmarks;
  }

  // Export startCamera function for external use
  export { startCamera };

  // ã‚­ãƒ£ãƒ³ãƒã‚¹åŒæœŸæ©Ÿèƒ½ã¯å‰Šé™¤

  // Export guidance state
  export { showPoseGuidance, poseGuidanceMessage, poseGuidanceType };

  // å§¿å‹¢ã¨è¡¨æƒ…ã‚’çµ±åˆã—ãŸã‚¬ã‚¤ãƒ€ãƒ³ã‚¹åˆ¤å®š
  function determineGuidance(
    pose: any,
    expression: ExpressionData | null,
    landmarks: any[]
  ) {
    // 1. ã¾ãšå§¿å‹¢ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    const poseGuidance = getPoseGuidanceData(pose);

    // å§¿å‹¢ã«å•é¡ŒãŒã‚ã‚‹å ´åˆã¯å§¿å‹¢ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’å„ªå…ˆ
    if (poseGuidance?.type !== PoseGuidanceType.SUCCESS) {
      return {
        show: showPoseGuidance,
        message: poseGuidanceMessage,
        type: poseGuidanceType,
        direction: getGuidanceDirection(pose),
        nosePosition: getNosePosition(landmarks),
        source: 'pose',
      };
    }

    // 2. å§¿å‹¢OKã®å ´åˆã€è¡¨æƒ…ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆè¡¨æƒ…æ¤œçŸ¥ãŒæœ‰åŠ¹ãªå ´åˆã®ã¿ï¼‰
    if (enableExpressionDetection === true && expression) {
      const expressionGuidance = getExpressionGuidanceData(expression);
      if (expressionGuidance) {
        return {
          show: true,
          message: expressionGuidance.message,
          type: expressionGuidance.type,
          direction: expressionGuidance.direction,
          nosePosition: getNosePosition(landmarks),
          source: 'expression',
        };
      }
    }

    // ã™ã¹ã¦OKã®å ´åˆ
    return {
      show: true,
      message: POSE_GUIDANCE_MAP.perfect.message,
      type: POSE_GUIDANCE_MAP.perfect.type,
      direction: null,
      nosePosition: getNosePosition(landmarks),
      source: 'success',
    };
  }

  // è¡¨æƒ…å•é¡Œã®å„ªå…ˆé †ä½ä»˜ããƒã‚§ãƒƒã‚¯
  function getExpressionGuidanceData(
    expression: ExpressionData
  ): PoseGuidanceData | null {
    if (!expression.isCalibrated) {
      return POSE_GUIDANCE_MAP.expressionCalibrating;
    }

    // ExpressionAnalyzerã®è¨­å®šå€¤ã‚’ä½¿ç”¨ã—ã¦ä¸€è²«æ€§ã‚’ä¿ã¤
    const settings = expressionAnalyzer.getSettings();

    // å„ªå…ˆé †ä½ï¼šç¬‘é¡” > çœ‰ > ç›®ã®åŠ›ã¿
    // ExpressionAnalyzerã¨åŒã˜æ¡ä»¶ã‚’ä½¿ç”¨ï¼ˆ>= ã‹ã‚‰ < ã¸ã®å¦å®šã§ä¸€è‡´ã•ã›ã‚‹ï¼‰
    if (expression.mouthSmile >= settings.smileThreshold) {
      return POSE_GUIDANCE_MAP.smileTooMuch;
    }
    if (expression.eyebrowRaise >= settings.eyebrowThreshold) {
      return POSE_GUIDANCE_MAP.eyebrowRaised;
    }
    if (expression.eyeTension >= settings.eyeTensionThreshold) {
      return POSE_GUIDANCE_MAP.eyeTension;
    }

    return null; // è¡¨æƒ…ã«å•é¡Œãªã—
  }
</script>

<!-- This component doesn't render anything directly -->
<!-- It only handles face detection logic and dispatches events -->
