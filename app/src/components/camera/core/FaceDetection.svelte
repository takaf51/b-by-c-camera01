<script lang="ts">
  import { onMount, onDestroy, createEventDispatcher } from 'svelte';
  import { FaceMesh } from '@mediapipe/face_mesh/face_mesh';
  import {
    drawConnectors,
    FACEMESH_TESSELATION,
    FACEMESH_RIGHT_EYE,
    FACEMESH_LEFT_EYE,
    FACEMESH_FACE_OVAL,
    FACEMESH_LIPS,
  } from '@mediapipe/drawing_utils/drawing_utils';
  import {
    PoseGuidanceDirection,
    PoseGuidanceType,
    POSE_GUIDANCE_MAP,
    type PoseGuidanceData,
  } from '../../../types/camera';
  import {
    ExpressionAnalyzer,
    type ExpressionData,
  } from '../../../lib/ExpressionAnalyzer';

  const dispatch = createEventDispatcher();

  // Props
  export let videoElement: HTMLVideoElement | undefined = undefined;
  export let canvasElement: HTMLCanvasElement | undefined = undefined;
  export let showMesh: boolean = true;
  export let currentMode: string = 'idle';
  // mirrorMode ã¯ä½¿ç”¨ã—ãªã„ãŸã‚å‰Šé™¤

  // Constants
  export const CAPTURE_COUNT: number = 1;
  export let CaptureMode: any;

  // MediaPipe instances
  let faceMesh: any;
  let camera: any;
  let canvasCtx: CanvasRenderingContext2D | null = null;
  let isStartingCamera = false;

  // Face detection state
  let faceDetectionCount = 0;
  let faceDetected = false;
  let faceDetectionStartTime: number | null = null;
  let faceLandmarks: any = null;

  // Expression analysis
  let expressionAnalyzer = new ExpressionAnalyzer();
  let currentExpression: ExpressionData | null = null;

  // Video dimensions for accurate coordinate transformation
  let currentVideoWidth = 0;
  let currentVideoHeight = 0;

  // Constants - PHPç‰ˆã¨åŒã˜å³ã—ã„è¨­å®š
  const FACE_DETECTION_THRESHOLD = 5; // Increased from 3 to 5
  const FACE_DETECTION_DELAY = 3.0; // å§¿å‹¢å®‰å®šå¾Œã®è‡ªå‹•æ’®å½±ã¾ã§ã®å¾…æ©Ÿæ™‚é–“ã‚’3ç§’ã«è¨­å®š
  // const STABILITY_TIME = 1.5; // ä¸è¦ã«ãªã£ãŸãŸã‚å‰Šé™¤ï¼ˆFACE_DETECTION_DELAYã‚’ä½¿ç”¨ï¼‰
  const THRESHOLDS = {
    roll: 10.0, // Reduced from 15.0 to 10.0 degrees
    pitch: 10.0, // Reduced from 15.0 to 10.0 degrees
    yaw: 10.0, // Reduced from 15.0 to 10.0 degrees
  };

  // Face size and quality thresholds like PHP version
  const MIN_FACE_SIZE = 0.15; // Minimum face size relative to image
  const MIN_FACE_QUALITY = 0.6; // Minimum face quality score

  // Pose and stability tracking
  let stablePosition = false;
  let stableStartTime: number | null = null;
  let stableFrameCount = 0;
  let progress = 0;

  // Guidance
  let poseGuidanceMessage = '';
  let poseGuidanceType = '';
  let showPoseGuidance = false;
  let lastGuidanceUpdate = 0;
  let lastGuidanceMessage = '';
  const GUIDANCE_UPDATE_INTERVAL = 100; // ã‚ˆã‚Šé »ç¹ã«ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’æ›´æ–°
  // GUIDANCE_DISPLAY_DURATION ã¯ä½¿ç”¨ã—ãªã„ï¼ˆç¶™ç¶šè¡¨ç¤ºã®ãŸã‚ï¼‰

  // syncIntervalå¤‰æ•°ã¯å‰Šé™¤

  onMount(async () => {
    try {
      await initializeMediaPipe();
    } catch (error) {
      dispatch('error', {
        message:
          'Face detection initialization failed: ' +
          (error instanceof Error ? error.message : String(error)),
      });
    }
  });

  // Public method to reset detection state
  export function resetDetectionState() {
    // Reset all detection-related variables
    stablePosition = false;
    stableFrameCount = 0;
    lastGuidanceUpdate = 0;
    showPoseGuidance = false;
    poseGuidanceMessage = '';
    poseGuidanceType = '';

    // Reset expression analysis
    expressionAnalyzer.resetCalibration();
    currentExpression = null;
  }

  onDestroy(() => {
    completeCleanup();
  });

  // Remove automatic camera starting - now controlled externally

  // Watch for mode changes (debug disabled)
  // $: if (currentMode) { console.log('ğŸ“± Mode changed:', currentMode); }

  async function initializeMediaPipe() {
    faceMesh = new FaceMesh({
      locateFile: (file: string) => {
        return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
      },
    });

    // Use same settings as PHP version
    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.7, // Increased from 0.5
      minTrackingConfidence: 0.7, // Increased from 0.5
      selfieMode: false,
      staticImageMode: false,
    });

    faceMesh.onResults(onResults);
  }

  // ã‚­ãƒ£ãƒ³ãƒã‚¹åŒæœŸæ©Ÿèƒ½ã¯å‰Šé™¤

  async function startCamera() {
    if (!videoElement || !faceMesh) {
      return;
    }

    if (isStartingCamera) {
      return;
    }

    isStartingCamera = true;
    try {
      // MediaPipe Camera utilsã‚’ä½¿ã‚ãšã«ç‹¬è‡ªã§ã‚«ãƒ¡ãƒ©ã‚’åˆ¶å¾¡
      // ã‚¹ãƒãƒ›å‘ã‘ã«ç¸¦å‘ãã®ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å–å¾—
      const isMobile = /iPhone|iPad|Android/i.test(navigator.userAgent);
      const isPortrait = window.innerHeight > window.innerWidth;

      let constraints: MediaStreamConstraints | undefined;
      let finalStream: MediaStream;

      // ã‚¹ãƒãƒ›ç¸¦å‘ãã®å ´åˆã€è¤‡æ•°ã®è§£åƒåº¦ã‚’è©¦ã™
      if (isMobile && isPortrait) {
        // åˆ©ç”¨å¯èƒ½ãªå…¨è§£åƒåº¦ã‚’å–å¾—ã—ã¦ç¸¦å‘ãã‚’æ¢ã™
        try {
          const devices = await navigator.mediaDevices.enumerateDevices();
          const videoDevices = devices.filter(
            device => device.kind === 'videoinput'
          );
          console.log('ğŸ“± Available video devices:', videoDevices.length);

          // ã¾ãšã¯åˆ¶ç´„ãªã—ã§ã‚«ãƒ¡ãƒ©èƒ½åŠ›ã‚’ç¢ºèª
          const testStream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: 'user' },
          });
          const testTrack = testStream.getVideoTracks()[0];
          const capabilities = testTrack.getCapabilities();
          testStream.getTracks().forEach(track => track.stop());

          console.log('ğŸ“· Camera capabilities:', capabilities);

          // åˆ©ç”¨å¯èƒ½ãªè§£åƒåº¦ã‹ã‚‰ç¸¦å‘ãã‚’å„ªå…ˆçš„ã«é¸æŠ
          const availableResolutions = [];
          if (capabilities.width && capabilities.height) {
            const maxWidth = capabilities.width.max || 1920;
            const maxHeight = capabilities.height.max || 1080;
            console.log(`ğŸ“ Max resolution: ${maxWidth}x${maxHeight}`);

            // ç¸¦å‘ãè§£åƒåº¦ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆ
            if (maxHeight >= maxWidth) {
              // ã™ã§ã«ç¸¦é•·ã®å ´åˆ
              availableResolutions.push({ width: maxWidth, height: maxHeight });
            } else {
              // æ¨ªé•·ã®å ´åˆã€ç¸¦æ¨ªã‚’å…¥ã‚Œæ›¿ãˆã¦ç¸¦å‘ãã«ã™ã‚‹
              availableResolutions.push({ width: maxHeight, height: maxWidth });
              availableResolutions.push({ width: maxWidth, height: maxHeight });
            }
          }
        } catch (e) {
          console.log('âŒ Failed to get capabilities:', e);
        }

        // ç”»é¢ã‚µã‚¤ã‚ºã‹ã‚‰å‹•çš„ã«resolutionPatternsã‚’è¨ˆç®—
        const screenWidth = window.innerWidth;
        const screenHeight = window.innerHeight;
        const screenAspectRatio = screenWidth / screenHeight;

        console.log('ğŸ“± Screen info for resolution calculation:', {
          screenWidth,
          screenHeight,
          screenAspectRatio: screenAspectRatio.toFixed(3),
        });

        // ã‚¹ãƒãƒ›ã‚«ãƒ¡ãƒ©ã«é©ã—ãŸè§£åƒåº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆï¼ˆç¸¦é•·ã§ã‚‚æ¨ªé•·è§£åƒåº¦ã‚’ä½¿ç”¨ï¼‰
        const resolutionPatterns = [
          // é«˜è§£åƒåº¦ï¼ˆæ­£æ–¹å½¢ã«è¿‘ã„ï¼‰
          { width: 1080, height: 1080, aspectRatio: 1.0 },
          { width: 960, height: 1280, aspectRatio: 0.75 }, // 3:4
          { width: 720, height: 960, aspectRatio: 0.75 }, // 3:4
          // 4:3ï¼ˆã‚«ãƒ¡ãƒ©ã®æ¨™æº–ï¼‰
          { width: 960, height: 720, aspectRatio: 4 / 3 },
          { width: 640, height: 480, aspectRatio: 4 / 3 },
          // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨
          { width: 480, height: 640, aspectRatio: 0.75 },
          { width: 360, height: 480, aspectRatio: 0.75 },
        ];

        console.log('ğŸ“± Generated resolution patterns:', resolutionPatterns);

        let stream = null;
        let successfulPattern = null;

        for (const pattern of resolutionPatterns) {
          try {
            constraints = {
              video: {
                facingMode: 'user',
                width: { ideal: pattern.width },
                height: { ideal: pattern.height },
                aspectRatio: { ideal: pattern.aspectRatio },
                // exactã‚„min/maxã‚’å‰Šé™¤ã—ã¦åˆ¶ç´„ã‚’ç·©å’Œ
              },
              audio: false,
            };

            console.log(
              `ğŸ“± Trying resolution: ${pattern.width}x${pattern.height}`
            );
            stream = await navigator.mediaDevices.getUserMedia(constraints);
            successfulPattern = pattern;
            console.log(
              `âœ… Successfully got stream with: ${pattern.width}x${pattern.height}`
            );
            break;
          } catch (e) {
            console.log(
              `âŒ Failed with ${pattern.width}x${pattern.height}:`,
              (e as Error).message
            );
          }
        }

        if (!stream) {
          // ç‰¹å®šã®ãƒ‡ãƒã‚¤ã‚¹IDã‚’æŒ‡å®šã—ã¦è©¦ã™
          const devices = await navigator.mediaDevices.enumerateDevices();
          const videoDevices = devices.filter(
            device => device.kind === 'videoinput'
          );
          console.log(
            'ğŸ“± Trying specific camera devices:',
            videoDevices.length
          );

          for (const device of videoDevices) {
            console.log(`ğŸ“· Trying device: ${device.label || device.deviceId}`);
            for (const pattern of resolutionPatterns) {
              try {
                constraints = {
                  video: {
                    deviceId: { exact: device.deviceId },
                    width: { ideal: pattern.width },
                    height: { ideal: pattern.height },
                    aspectRatio: { ideal: pattern.aspectRatio },
                  },
                  audio: false,
                };

                stream = await navigator.mediaDevices.getUserMedia(constraints);
                successfulPattern = pattern;
                console.log(
                  `âœ… Success with device ${device.label} at ${pattern.width}x${pattern.height}`
                );
                break;
              } catch (e) {
                // æ¬¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™
              }
            }
            if (stream) break;
          }
        }

        if (!stream) {
          // æœ€å¾Œã®æ‰‹æ®µï¼šåˆ¶ç´„ãªã—ã§å–å¾—
          console.log('ğŸ“± All attempts failed, using fallback');
          constraints = {
            video: {
              facingMode: 'user',
            },
            audio: false,
          };
          stream = await navigator.mediaDevices.getUserMedia(constraints);
        }

        finalStream = stream;
      } else if (isMobile && !isPortrait) {
        // ã‚¹ãƒãƒ›æ¨ªå‘ãã®å ´åˆ
        constraints = {
          video: {
            facingMode: 'user',
            width: { min: 640, ideal: 1280, max: 1920 },
            height: { min: 480, ideal: 720, max: 1080 },
            aspectRatio: { ideal: 1.777 }, // 16:9 = 1.777
          },
          audio: false,
        };
        finalStream = await navigator.mediaDevices.getUserMedia(constraints);
      } else {
        // PCã®å ´åˆ
        constraints = {
          video: {
            facingMode: 'user',
            width: { ideal: 1280 },
            height: { ideal: 720 },
            aspectRatio: { ideal: 1.777 },
          },
          audio: false,
        };
        finalStream = await navigator.mediaDevices.getUserMedia(constraints);
      }

      console.log(
        'ğŸ“± Final constraints used:',
        typeof constraints !== 'undefined' ? constraints : 'No constraints set'
      );

      const stream = finalStream;

      // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®å®Ÿéš›ã®è¨­å®šã‚’ç¢ºèª
      const videoTrack = stream.getVideoTracks()[0];
      const settings = videoTrack.getSettings();
      console.log('ğŸ“· Actual camera settings:', {
        width: settings.width,
        height: settings.height,
        aspectRatio: settings.aspectRatio,
        facingMode: settings.facingMode,
      });

      videoElement.srcObject = stream;
      await videoElement.play();

      // ãƒ“ãƒ‡ã‚ªã®å®Ÿéš›ã®ã‚µã‚¤ã‚ºã‚’ç¢ºèª
      console.log('ğŸ“º Video element dimensions:', {
        videoWidth: videoElement.videoWidth,
        videoHeight: videoElement.videoHeight,
        clientWidth: videoElement.clientWidth,
        clientHeight: videoElement.clientHeight,
      });

      // MediaPipeã«ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é€ã‚‹å‡¦ç†ã‚’ç‹¬è‡ªã«å®Ÿè£…
      let animationId: number;
      const sendFrame = async () => {
        if (faceMesh && videoElement && videoElement.readyState >= 2) {
          try {
            await faceMesh.send({ image: videoElement });
          } catch (error) {
            console.error('Error sending frame to FaceMesh:', error);
          }
        }
        animationId = requestAnimationFrame(sendFrame);
      };

      // ãƒ•ãƒ¬ãƒ¼ãƒ é€ä¿¡ã‚’é–‹å§‹
      sendFrame();

      // ã‚«ãƒ¡ãƒ©åœæ­¢æ™‚ã«ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ãŸã‚ã«ä¿å­˜
      camera = {
        stop: () => {
          if (animationId) {
            cancelAnimationFrame(animationId);
          }
          if (stream) {
            stream.getTracks().forEach(track => track.stop());
          }
        },
      };

      // Wait for video to be ready
      if (videoElement.readyState < 2) {
        await new Promise(resolve => {
          const checkReady = () => {
            if (videoElement.readyState >= 2) {
              resolve(true);
            } else {
              setTimeout(checkReady, 50);
            }
          };
          checkReady();
        });
      }

      // Reset detection state when camera starts
      faceDetected = false;
      faceDetectionCount = 0;
      faceDetectionStartTime = null;
      stablePosition = false;
      stableStartTime = null;
      progress = 0;

      dispatch('cameraStarted');
    } catch (error) {
      dispatch('error', {
        message:
          'Camera startup failed: ' +
          (error instanceof Error ? error.message : String(error)),
      });
    } finally {
      isStartingCamera = false;
    }
  }

  function onResults(results: any) {
    if (!canvasCtx && canvasElement) {
      canvasCtx = canvasElement.getContext('2d')!;
    }

    if (!canvasCtx || !canvasElement) return;

    // ãƒ“ãƒ‡ã‚ªã®å®Ÿéš›ã®ã‚µã‚¤ã‚ºã‚’å–å¾—
    const videoWidth =
      results.image.width ||
      results.image.videoWidth ||
      videoElement?.videoWidth ||
      720;
    const videoHeight =
      results.image.height ||
      results.image.videoHeight ||
      videoElement?.videoHeight ||
      1280;

    // ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚ºã‚’ãƒ“ãƒ‡ã‚ªã®ã‚µã‚¤ã‚ºã«å®Œå…¨ã«ä¸€è‡´ã•ã›ã‚‹
    if (
      canvasElement.width !== videoWidth ||
      canvasElement.height !== videoHeight
    ) {
      canvasElement.width = videoWidth;
      canvasElement.height = videoHeight;
      console.log('ğŸ“ Canvas resized to match video:', {
        width: videoWidth,
        height: videoHeight,
      });
    }

    // Clear canvas
    canvasCtx.save();
    canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

    // Save current video dimensions for coordinate transformation
    currentVideoWidth = videoWidth;
    currentVideoHeight = videoHeight;

    // ãƒ“ãƒ‡ã‚ªã‚’ãã®ã¾ã¾ã®ã‚µã‚¤ã‚ºã§æç”»ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãªã—ï¼‰
    canvasCtx.drawImage(results.image, 0, 0, videoWidth, videoHeight);

    // Debug: Log drawing dimensions (only occasionally to avoid spam)
    if (Math.random() < 0.01) {
      // 1% chance to log
    }

    const hasFace =
      results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0;
    // MediaPipeçµæœã®ãƒ­ã‚°ã¯å‰Šé™¤ï¼ˆå¿…è¦æ™‚ã®ã¿æœ‰åŠ¹åŒ–ï¼‰
    // console.log('ğŸ“¸ MediaPipe results:', { hasFace, faceCount: results.multiFaceLandmarks?.length || 0 });

    if (hasFace) {
      const landmarks = results.multiFaceLandmarks[0];
      faceLandmarks = landmarks;

      // Calculate pose
      const pose = calculatePose(landmarks);
      // å§¿å‹¢è¨ˆç®—ã®ãƒ­ã‚°ã¯å‰Šé™¤ï¼ˆå¿…è¦æ™‚ã®ã¿æœ‰åŠ¹åŒ–ï¼‰
      // console.log('ğŸ“ Calculated pose:', pose);

      // Analyze expression
      currentExpression = expressionAnalyzer.analyzeExpression(landmarks);

      updateStability(pose);

      if (showMesh) {
        drawFaceMesh(landmarks);
      }

      // Face detection stability
      faceDetectionCount++;

      if (!faceDetected && faceDetectionCount >= FACE_DETECTION_THRESHOLD) {
        faceDetected = true;

        if (currentMode !== CaptureMode?.CAMERA_STARTUP) {
          faceDetectionStartTime = performance.now();

          // ãƒ‡ã‚¶ã‚¤ãƒ³ã«ãªã„ãŸã‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã—ãªã„
        }
      }

      // Check auto capture (exclude preview modes)
      if (
        currentMode !== CaptureMode?.CAMERA_STARTUP &&
        currentMode !== CaptureMode?.PREVIEW_BEFORE &&
        currentMode !== CaptureMode?.PREVIEW_AFTER
      ) {
        checkAutoCapture();
      }

      // çµ±åˆã‚¬ã‚¤ãƒ€ãƒ³ã‚¹åˆ¤å®šï¼ˆå§¿å‹¢å„ªå…ˆã€è¡¨æƒ…ã¯å§¿å‹¢OKã®å ´åˆã®ã¿ï¼‰
      const guidanceInfo = determineGuidance(
        pose,
        currentExpression,
        landmarks
      );

      dispatch('faceDetected', {
        landmarks,
        pose,
        expression: currentExpression, // è¡¨æƒ…ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        stable: stablePosition,
        progress,
        guidance: guidanceInfo,
      });
    } else {
      // No face detected
      // console.log('âŒ No face detected'); // ãƒ­ã‚°å‰Šé™¤
      handleNoFaceDetected();
    }

    drawUIOverlays();
    canvasCtx.restore();
  }

  function drawFaceMesh(landmarks: any) {
    if (!canvasCtx) return;

    drawConnectors(canvasCtx, landmarks, FACEMESH_TESSELATION, {
      color: '#C0C0C070',
      lineWidth: 1,
    });
    drawConnectors(canvasCtx, landmarks, FACEMESH_RIGHT_EYE, {
      color: '#FF3030',
    });
    drawConnectors(canvasCtx, landmarks, FACEMESH_LEFT_EYE, {
      color: '#30FF30',
    });
    drawConnectors(canvasCtx, landmarks, FACEMESH_FACE_OVAL, {
      color: '#E0E0E0',
    });
    drawConnectors(canvasCtx, landmarks, FACEMESH_LIPS, {
      color: '#E0E0E0',
    });
  }

  function handleNoFaceDetected() {
    faceDetectionCount = 0;

    if (faceDetected) {
      faceDetected = false;
      faceDetectionStartTime = null;
    }

    stablePosition = false;
    stableStartTime = null;
    progress = 0;

    // Clear pose guidance in CAMERA_STARTUP mode
    if (currentMode === CaptureMode?.CAMERA_STARTUP) {
      showPoseGuidance = false;
      poseGuidanceMessage = '';
    }

    // ãƒ‡ã‚¶ã‚¤ãƒ³ã«ãªã„ãŸã‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯é€ä¿¡ã—ãªã„

    dispatch('faceDetected', {
      landmarks: null,
      pose: null,
      stable: false,
      progress: 0,
    });

    showPoseGuidance = false;
    lastGuidanceMessage = '';
  }

  function calculateFaceSize(landmarks: any): number {
    try {
      // é¡”ã®å¢ƒç•Œã‚’è¨ˆç®—
      let minX = 1,
        maxX = 0,
        minY = 1,
        maxY = 0;

      // é¡”ã®è¼ªéƒ­ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦å¢ƒç•Œã‚’è¨ˆç®—
      const faceContourIndices = [
        10, 151, 9, 8, 168, 6, 197, 195, 5, 4, 1, 19, 94, 125, 142, 36, 205,
        206, 207, 213, 192, 147, 187, 207, 206, 205, 36, 142, 125, 94, 19, 1, 4,
        5, 195, 197, 6, 168, 8, 9, 151, 10,
      ];

      for (const index of faceContourIndices) {
        if (landmarks[index]) {
          minX = Math.min(minX, landmarks[index].x);
          maxX = Math.max(maxX, landmarks[index].x);
          minY = Math.min(minY, landmarks[index].y);
          maxY = Math.max(maxY, landmarks[index].y);
        }
      }

      // é¡”ã®ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ï¼ˆç”»åƒã«å¯¾ã™ã‚‹ç›¸å¯¾ã‚µã‚¤ã‚ºï¼‰
      const faceWidth = maxX - minX;
      const faceHeight = maxY - minY;
      const faceSize = Math.sqrt(
        faceWidth * faceWidth + faceHeight * faceHeight
      );

      return faceSize;
    } catch (error) {
      return 0;
    }
  }

  function calculatePose(landmarks: any) {
    // PHPç‰ˆã¨å®Œå…¨ã«åŒã˜å§¿å‹¢è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
    try {
      // ç‰¹å¾´ç‚¹ã®å–å¾—ï¼ˆPHPã¨åŒã˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰
      const nose = landmarks[1];
      const leftEye = landmarks[33];
      const rightEye = landmarks[263];
      const leftMouth = landmarks[61];
      const rightMouth = landmarks[291];

      if (!nose || !leftEye || !rightEye || !leftMouth || !rightMouth) {
        throw new Error('Required landmarks not found');
      }

      // ãƒ­ãƒ¼ãƒ«ï¼ˆZè»¸å›è»¢ï¼‰- ç›®ã®å‚¾ã - ãƒŸãƒ©ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œ
      const eyeDiffY = rightEye.y - leftEye.y;
      const eyeDiffX = rightEye.x - leftEye.x;
      const roll = (-Math.atan2(eyeDiffY, eyeDiffX) * 180) / Math.PI;

      // ãƒ”ãƒƒãƒï¼ˆXè»¸å›è»¢ï¼‰- ç¸¦æ–¹å‘ã®å‚¾ã - ä¿®æ­£ç‰ˆ
      const eyeCenter = {
        y: (leftEye.y + rightEye.y) / 2,
        z: (leftEye.z + rightEye.z) / 2,
      };

      // é¼»ã¨ç›®ã®ä¸­å¿ƒã®ä½ç½®é–¢ä¿‚
      const eyeNoseY = eyeCenter.y - nose.y;
      const eyeNoseZ = eyeCenter.z - nose.z;

      // è§’åº¦è¨ˆç®— - ç¬¦å·ã¨å¼•æ•°ã‚’èª¿æ•´
      let rawPitch = (-Math.atan2(eyeNoseZ, eyeNoseY) * 180) / Math.PI;

      // 180åº¦å•é¡Œã®è§£æ±º
      if (rawPitch > 90) {
        rawPitch = rawPitch - 180;
      } else if (rawPitch < -90) {
        rawPitch = rawPitch + 180;
      }

      // æœ€çµ‚çš„ãªãƒ”ãƒƒãƒå€¤ï¼ˆãƒ‡ãƒã‚¤ã‚¹åˆ¥ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼‰
      const screenWidth = window.innerWidth;
      let pitch;
      if (screenWidth <= 480) {
        // iPhone: -8åº¦
        pitch = rawPitch - 65 + 15;
      } else if (screenWidth <= 1024) {
        // iPad: +10åº¦ï¼ˆå…ƒã®é‡è¦ãªèª¿æ•´ï¼‰
        pitch = rawPitch - 65 + 10;
      } else {
        // PC: ã‚ªãƒ•ã‚»ãƒƒãƒˆãªã—
        pitch = rawPitch - 65;
      }

      // ãƒ¨ãƒ¼ï¼ˆYè»¸å›è»¢ï¼‰- æ¨ªæ–¹å‘ã®å‘ã
      const eyeMidPoint = {
        x: (leftEye.x + rightEye.x) / 2,
      };
      const noseMidOffset = eyeMidPoint.x - nose.x;
      const yaw = noseMidOffset * 500;

      // é¡”ã®ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
      const faceSize = calculateFaceSize(landmarks);

      // è·é›¢ã¨å“è³ªã®è¨ˆç®—
      const eyeDistance = Math.sqrt(eyeDiffX * eyeDiffX + eyeDiffY * eyeDiffY);
      const distance = Math.max(0.5, Math.min(2.0, 1.0 / eyeDistance));
      const quality = Math.max(0.0, Math.min(1.0, faceSize * 2));

      const result = {
        roll: Math.round(roll * 10) / 10,
        pitch: Math.round(pitch * 10) / 10,
        yaw: Math.round(yaw * 10) / 10,
        distance: Math.round(distance * 100) / 100,
        quality: Math.round(quality * 100) / 100,
        faceSize: Math.round(faceSize * 1000) / 1000,
      };

      return result;
    } catch (error) {
      return {
        roll: 0,
        pitch: 0,
        yaw: 0,
        distance: 1.0,
        quality: 0.0,
        faceSize: 0.0,
      };
    }
  }

  function updateStability(pose: any) {
    const now = performance.now();

    // PHPç‰ˆã¨åŒã˜å³ã—ã„æ¡ä»¶
    const isGoodPose =
      Math.abs(pose.roll) < THRESHOLDS.roll &&
      Math.abs(pose.pitch) < THRESHOLDS.pitch &&
      Math.abs(pose.yaw) < THRESHOLDS.yaw &&
      pose.quality >= MIN_FACE_QUALITY &&
      pose.faceSize >= MIN_FACE_SIZE;

    // å§¿å‹¢å®‰å®šæ€§ãƒã‚§ãƒƒã‚¯ã®ãƒ­ã‚°ã¯å‰Šé™¤ï¼ˆå¿…è¦æ™‚ã®ã¿æœ‰åŠ¹åŒ–ï¼‰
    // console.log('ğŸ¯ Pose stability check:', { roll: pose.roll.toFixed(1), pitch: pose.pitch.toFixed(1), yaw: pose.yaw.toFixed(1), isGoodPose, progress: progress.toFixed(1) });

    if (isGoodPose) {
      if (!stablePosition) {
        stablePosition = true;
        stableStartTime = now;
        showPoseGuidance = true;
        poseGuidanceMessage = 'è‰¯ã„å§¿å‹¢ã§ã™ï¼ä¿æŒã—ã¦ãã ã•ã„';
        poseGuidanceType = 'success';

        // æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯2ç§’å¾Œã«éè¡¨ç¤ºã«ã™ã‚‹
        setTimeout(() => {
          if (stablePosition) {
            showPoseGuidance = false;
          }
        }, 2000);
      }

      if (stableStartTime) {
        const elapsed = (now - stableStartTime) / 1000;
        // ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’å§¿å‹¢å®‰å®šå¾Œã®è‡ªå‹•æ’®å½±å¾…æ©Ÿæ™‚é–“ï¼ˆFACE_DETECTION_DELAYï¼‰ã«åˆã‚ã›ã‚‹
        progress = Math.min((elapsed / FACE_DETECTION_DELAY) * 100, 100);

        if (progress >= 100) {
        }
      }
    } else {
      if (stablePosition) {
      }
      stablePosition = false;
      stableStartTime = null;
      progress = 0;

      // Guidance messages
      if (now - lastGuidanceUpdate > GUIDANCE_UPDATE_INTERVAL) {
        updatePoseGuidance(pose);
        lastGuidanceUpdate = now;
      }
    }
  }

  // å§¿å‹¢ã«åŸºã¥ã„ã¦ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆEnumãƒ™ãƒ¼ã‚¹ï¼‰
  function getPoseGuidanceData(pose: any): PoseGuidanceData | null {
    if (!pose) return null;

    // å„ªå…ˆé †ä½ã«å¾“ã£ã¦åˆ¤å®šï¼ˆPHPç‰ˆã¨åŒã˜é †ç•ªï¼‰
    if (pose.faceSize < MIN_FACE_SIZE) {
      return POSE_GUIDANCE_MAP.tooFar;
    } else if (pose.quality < MIN_FACE_QUALITY) {
      return POSE_GUIDANCE_MAP.lowQuality;
    } else if (Math.abs(pose.roll) >= THRESHOLDS.roll) {
      return pose.roll > 0
        ? POSE_GUIDANCE_MAP.rollPositive
        : POSE_GUIDANCE_MAP.rollNegative;
    } else if (Math.abs(pose.pitch) >= THRESHOLDS.pitch) {
      return pose.pitch > 0
        ? POSE_GUIDANCE_MAP.pitchPositive
        : POSE_GUIDANCE_MAP.pitchNegative;
    } else if (Math.abs(pose.yaw) >= THRESHOLDS.yaw) {
      return pose.yaw > 0
        ? POSE_GUIDANCE_MAP.yawPositive
        : POSE_GUIDANCE_MAP.yawNegative;
    } else {
      return POSE_GUIDANCE_MAP.perfect;
    }
  }

  function getGuidanceDirection(pose: any): PoseGuidanceDirection | null {
    const guidanceData = getPoseGuidanceData(pose);
    return guidanceData?.direction || null;
  }

  // PHPã¨åŒã˜é¼»ã®ä½ç½®è¨ˆç®—ï¼ˆå®Œå…¨ç§»æ¤ç‰ˆï¼‰
  function getNosePosition(landmarks: any) {
    if (
      !landmarks ||
      !canvasElement ||
      currentVideoWidth === 0 ||
      currentVideoHeight === 0
    ) {
      // Debug: Log why getNosePosition is returning null
      if (Math.random() < 0.1) {
        // 10% chance to avoid spam
      }
      return null;
    }

    // é¼»ã®å…ˆç«¯ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹1ï¼‰
    const nose = landmarks[1];
    if (!nose) return null;

    // onResultsé–¢æ•°ã¨åŒã˜ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”è¨ˆç®—ã‚’ä½¿ç”¨
    const videoWidth = currentVideoWidth;
    const videoHeight = currentVideoHeight;
    const canvasWidth = canvasElement.width;
    const canvasHeight = canvasElement.height;

    const videoAspect = videoWidth / videoHeight;
    const canvasAspect = canvasWidth / canvasHeight;

    let drawWidth, drawHeight, drawX, drawY;

    if (videoAspect > canvasAspect) {
      // Video is wider - fit to canvas height
      drawHeight = canvasHeight;
      drawWidth = drawHeight * videoAspect;
      drawX = (canvasWidth - drawWidth) / 2;
      drawY = 0;
    } else {
      // Video is taller - fit to canvas width
      drawWidth = canvasWidth;
      drawHeight = drawWidth / videoAspect;
      drawX = 0;
      drawY = (canvasHeight - drawHeight) / 2;
    }

    // å®Ÿéš›ã®æç”»é ˜åŸŸå†…ã§ã®åº§æ¨™è¨ˆç®—
    const noseX = (1 - nose.x) * drawWidth + drawX;
    const noseY = nose.y * drawHeight + drawY;

    // è¡¨ç¤ºã‚µã‚¤ã‚ºã«åˆã‚ã›ã¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    const canvasRect = canvasElement.getBoundingClientRect();
    const scaleX = canvasRect.width / canvasElement.width;
    const scaleY = canvasRect.height / canvasElement.height;

    const displayX = noseX * scaleX;
    const displayY = noseY * scaleY;

    // Debug: Log successful nose position calculation
    if (Math.random() < 0.05) {
      // 5% chance to avoid spam
    }

    return { x: displayX, y: displayY };
  }

  function updatePoseGuidance(pose: any) {
    // Don't show pose guidance in CAMERA_STARTUP mode
    if (currentMode === CaptureMode?.CAMERA_STARTUP) {
      return;
    }

    // ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆEnumãƒ™ãƒ¼ã‚¹ï¼‰
    const guidanceData = getPoseGuidanceData(pose);

    if (!guidanceData) return;

    const { message, type } = guidanceData;

    if (message) {
      poseGuidanceMessage = message;
      poseGuidanceType = type;
      showPoseGuidance = true;
      lastGuidanceMessage = message;

      // å§¿å‹¢ãŒæ‚ªã„é–“ã¯ç¶™ç¶šçš„ã«è¡¨ç¤ºï¼ˆåŒã˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã‚‚ç¶™ç¶šè¡¨ç¤ºï¼‰
    }
  }

  // PHPã¨åŒã˜ãƒ”ãƒã‚­ã‚ªæ£’ï¼ˆãƒ”ãƒ³ã‚¯è»¸ï¼‰æç”»æ©Ÿèƒ½
  function drawPoseAxes(landmarks: any) {
    if (!canvasCtx || !canvasElement) return;

    // ç¾åœ¨ã®å§¿å‹¢ã‚’è¨ˆç®—
    const pose = calculatePose(landmarks);

    // é¡åƒè¡¨ç¤ºã«å¯¾å¿œã™ã‚‹ãŸã‚ã®å¤‰æ›
    canvasCtx.scale(-1, 1);
    canvasCtx.translate(-canvasElement.width, 0);

    const nose = landmarks[1];
    const scale = 0.2; // è»¸ã®é•·ã•

    // åº§æ¨™è»¸ã®æç”»ï¼ˆé¼»ã‹ã‚‰ä¼¸ã³ã‚‹ãƒ”ãƒ³ã‚¯è»¸ï¼‰
    // ãƒŸãƒ©ãƒ¼ãƒªãƒ³ã‚°æ™‚ã®åº§æ¨™ã«å¤‰æ›
    const noseX = (1 - nose.x) * canvasElement.width;
    const noseY = nose.y * canvasElement.height;

    // Zè»¸ï¼ˆãƒ”ãƒ³ã‚¯ï¼‰- ãƒ¨ãƒ¼ï¼ˆé¡”ã®å‘ãï¼‰ã«å¿œã˜ã¦æ–¹å‘ãŒå¤‰ã‚ã‚‹
    const zAxisX =
      noseX +
      Math.sin((pose.yaw * Math.PI) / 180) * scale * canvasElement.width;

    // å††æŸ±ã®æç”»ï¼ˆZè»¸ï¼‰
    const cylinderWidth = 12; // å††æŸ±ã®å¹…

    // ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§å††æŸ±åŠ¹æœã‚’ä½œæˆ
    const gradient = canvasCtx.createLinearGradient(
      noseX,
      noseY,
      zAxisX,
      noseY
    );
    gradient.addColorStop(0, '#E05179'); // ãƒ”ãƒ³ã‚¯è‰²ï¼ˆå§‹ç‚¹ï¼‰
    gradient.addColorStop(1, 'rgba(224, 81, 121, 0.8)'); // æ˜ã‚‹ã„ãƒ”ãƒ³ã‚¯è‰²ï¼ˆçµ‚ç‚¹ï¼‰

    // å††æŸ±ã®æœ¬ä½“ã‚’æç”»
    canvasCtx.beginPath();
    canvasCtx.moveTo(noseX, noseY - cylinderWidth / 2);
    canvasCtx.lineTo(zAxisX, noseY - cylinderWidth / 2);
    canvasCtx.lineTo(zAxisX, noseY + cylinderWidth / 2);
    canvasCtx.lineTo(noseX, noseY + cylinderWidth / 2);
    canvasCtx.closePath();
    canvasCtx.fillStyle = gradient;
    canvasCtx.fill();

    // çµ‚ç‚¹ã®å††ã‚’æç”»
    canvasCtx.beginPath();
    canvasCtx.arc(zAxisX, noseY, cylinderWidth / 2, 0, Math.PI * 2);
    canvasCtx.fillStyle = 'rgba(224, 81, 121, 0.8)';
    canvasCtx.fill();

    // å§‹ç‚¹ã®å††ã‚’æç”»
    canvasCtx.beginPath();
    canvasCtx.arc(noseX, noseY, cylinderWidth / 2, 0, Math.PI * 2);
    canvasCtx.fillStyle = '#E05179';
    canvasCtx.fill();
  }

  function checkAutoCapture() {
    if (!faceDetected || !stableStartTime) return;

    // å§¿å‹¢ãŒå®‰å®šã—ã¦ã‹ã‚‰ã®çµŒéæ™‚é–“ã‚’è¨ˆç®—
    const elapsed = (performance.now() - stableStartTime) / 1000;

    // å§¿å‹¢ãŒå®‰å®šã—ã¦ã‹ã‚‰3ç§’çµŒéã§æ’®å½±
    if (elapsed >= FACE_DETECTION_DELAY && stablePosition && progress >= 100) {
      dispatch('autoCapture', { landmarks: faceLandmarks });

      // Reset detection to prevent multiple captures
      faceDetectionStartTime = null;
      faceDetected = false;
      stablePosition = false;
      stableStartTime = null;
      progress = 0;
    }
  }

  function drawUIOverlays() {
    if (!canvasCtx || !canvasElement) return;

    // Save the current transformation matrix
    canvasCtx.save();

    // ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®ã¿æç”»ï¼ˆç™½ã„å††ã¯CSSã§è¡¨ç¤ºï¼‰
    if (
      currentMode !== CaptureMode?.CAMERA_STARTUP &&
      faceDetected &&
      stablePosition &&
      progress > 0
    ) {
      const centerX = canvasElement.width / 2;
      const centerY = canvasElement.height / 2;
      // CSS ã®ãƒã‚¹ã‚¯å††ã¨åŒã˜ã‚µã‚¤ã‚ºã«åˆã‚ã›ã‚‹ï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–å¯¾å¿œï¼‰
      const circleSize = Math.min(300, window.innerWidth * 0.5);
      const radius = circleSize / 2 - 10; // ãƒã‚¹ã‚¯å††ã®å†…å´ã«ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æç”»

      const progressAngle = (progress / 100) * 2 * Math.PI - Math.PI / 2;

      canvasCtx.beginPath();
      canvasCtx.arc(centerX, centerY, radius, -Math.PI / 2, progressAngle);
      canvasCtx.strokeStyle = progress >= 100 ? '#4CAF50' : '#FFA500';
      canvasCtx.lineWidth = 8;
      canvasCtx.stroke();
    }

    // ãƒ”ãƒã‚­ã‚ªæ£’ï¼ˆãƒ”ãƒ³ã‚¯è»¸ï¼‰ã®æç”» - PHPã¨åŒã˜å®Ÿè£…
    if (faceLandmarks && faceDetected) {
      drawPoseAxes(faceLandmarks);
    }

    // Restore the transformation matrix
    canvasCtx.restore();
  }

  function cleanup() {
    // Stop camera but don't destroy faceMesh (for reuse)
    if (camera) {
      camera.stop();
      camera = null;
    }

    // Stop video stream
    if (videoElement && videoElement.srcObject) {
      const stream = videoElement.srcObject as MediaStream;
      stream.getTracks().forEach(track => {
        track.stop();
      });
      videoElement.srcObject = null;
    }

    // Reset detection state
    faceDetected = false;
    faceDetectionCount = 0;
    faceDetectionStartTime = null;
    stablePosition = false;
    stableStartTime = null;
    progress = 0;
    isStartingCamera = false;
  }

  // Complete cleanup function for component destruction
  function completeCleanup() {
    cleanup();

    if (faceMesh) {
      faceMesh.close();
      faceMesh = null;
    }
  }

  // Export cleanup functions for external use
  export { cleanup, completeCleanup };

  // Export function to get current face landmarks
  export function getCurrentFaceLandmarks() {
    return faceLandmarks;
  }

  // Export startCamera function for external use
  export { startCamera };

  // ã‚­ãƒ£ãƒ³ãƒã‚¹åŒæœŸæ©Ÿèƒ½ã¯å‰Šé™¤

  // Export guidance state
  export { showPoseGuidance, poseGuidanceMessage, poseGuidanceType };

  // å§¿å‹¢ã¨è¡¨æƒ…ã‚’çµ±åˆã—ãŸã‚¬ã‚¤ãƒ€ãƒ³ã‚¹åˆ¤å®š
  function determineGuidance(
    pose: any,
    expression: ExpressionData | null,
    landmarks: any[]
  ) {
    // 1. ã¾ãšå§¿å‹¢ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    const poseGuidance = getPoseGuidanceData(pose);

    // å§¿å‹¢ã«å•é¡ŒãŒã‚ã‚‹å ´åˆã¯å§¿å‹¢ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’å„ªå…ˆ
    if (poseGuidance?.type !== PoseGuidanceType.SUCCESS) {
      return {
        show: showPoseGuidance,
        message: poseGuidanceMessage,
        type: poseGuidanceType,
        direction: getGuidanceDirection(pose),
        nosePosition: getNosePosition(landmarks),
        source: 'pose',
      };
    }

    // 2. å§¿å‹¢OKã®å ´åˆã€è¡¨æƒ…ã‚’ãƒã‚§ãƒƒã‚¯
    if (expression) {
      const expressionGuidance = getExpressionGuidanceData(expression);
      if (expressionGuidance) {
        return {
          show: true,
          message: expressionGuidance.message,
          type: expressionGuidance.type,
          direction: expressionGuidance.direction,
          nosePosition: getNosePosition(landmarks),
          source: 'expression',
        };
      }
    }

    // ã™ã¹ã¦OKã®å ´åˆ
    return {
      show: true,
      message: POSE_GUIDANCE_MAP.perfect.message,
      type: POSE_GUIDANCE_MAP.perfect.type,
      direction: null,
      nosePosition: getNosePosition(landmarks),
      source: 'success',
    };
  }

  // è¡¨æƒ…å•é¡Œã®å„ªå…ˆé †ä½ä»˜ããƒã‚§ãƒƒã‚¯
  function getExpressionGuidanceData(
    expression: ExpressionData
  ): PoseGuidanceData | null {
    if (!expression.isCalibrated) {
      return POSE_GUIDANCE_MAP.expressionCalibrating;
    }

    // å„ªå…ˆé †ä½ï¼šç¬‘é¡” > çœ‰ > ç›®ã®åŠ›ã¿
    if (expression.mouthSmile >= 0.3) {
      return POSE_GUIDANCE_MAP.smileTooMuch;
    }
    if (expression.eyebrowRaise >= 0.25) {
      return POSE_GUIDANCE_MAP.eyebrowRaised;
    }
    if (expression.eyeTension >= 0.3) {
      return POSE_GUIDANCE_MAP.eyeTension;
    }

    return null; // è¡¨æƒ…ã«å•é¡Œãªã—
  }
</script>

<!-- This component doesn't render anything directly -->
<!-- It only handles face detection logic and dispatches events -->
