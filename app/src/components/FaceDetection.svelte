<script lang="ts">
  import { onMount, onDestroy, createEventDispatcher } from 'svelte';
  import { FaceMesh } from '@mediapipe/face_mesh/face_mesh';
  import { Camera as MediaPipeCamera } from '@mediapipe/camera_utils/camera_utils';
  import {
    drawConnectors,
    FACEMESH_TESSELATION,
    FACEMESH_RIGHT_EYE,
    FACEMESH_LEFT_EYE,
    FACEMESH_FACE_OVAL,
    FACEMESH_LIPS,
  } from '@mediapipe/drawing_utils/drawing_utils';

  const dispatch = createEventDispatcher();

  // Props
  export let videoElement: HTMLVideoElement | undefined = undefined;
  export let canvasElement: HTMLCanvasElement | undefined = undefined;
  export let showMesh: boolean = true;
  export let currentMode: string = 'idle';
  // mirrorMode ã¯ä½¿ç”¨ã—ãªã„ãŸã‚å‰Šé™¤

  // Constants
  export const CAPTURE_COUNT: number = 1;
  export let CaptureMode: any;

  // MediaPipe instances
  let faceMesh: any;
  let camera: any;
  let canvasCtx: CanvasRenderingContext2D | null = null;
  let isStartingCamera = false;

  // Face detection state
  let faceDetectionCount = 0;
  let faceDetected = false;
  let faceDetectionStartTime: number | null = null;
  let faceLandmarks: any = null;

  // Constants - PHPç‰ˆã¨åŒã˜å³ã—ã„è¨­å®š
  const FACE_DETECTION_THRESHOLD = 5; // Increased from 3 to 5
  const FACE_DETECTION_DELAY = 3.0; // å§¿å‹¢å®‰å®šå¾Œã®è‡ªå‹•æ’®å½±ã¾ã§ã®å¾…æ©Ÿæ™‚é–“ã‚’3ç§’ã«è¨­å®š
  // const STABILITY_TIME = 1.5; // ä¸è¦ã«ãªã£ãŸãŸã‚å‰Šé™¤ï¼ˆFACE_DETECTION_DELAYã‚’ä½¿ç”¨ï¼‰
  const THRESHOLDS = {
    roll: 10.0, // Reduced from 15.0 to 10.0 degrees
    pitch: 10.0, // Reduced from 15.0 to 10.0 degrees
    yaw: 10.0, // Reduced from 15.0 to 10.0 degrees
  };

  // Face size and quality thresholds like PHP version
  const MIN_FACE_SIZE = 0.15; // Minimum face size relative to image
  const MIN_FACE_QUALITY = 0.6; // Minimum face quality score

  // Pose and stability tracking
  let stablePosition = false;
  let stableStartTime: number | null = null;
  let stableFrameCount = 0;
  let progress = 0;

  // Guidance
  let poseGuidanceMessage = '';
  let poseGuidanceType = '';
  let showPoseGuidance = false;
  let lastGuidanceUpdate = 0;
  let lastGuidanceMessage = '';
  const GUIDANCE_UPDATE_INTERVAL = 100; // ã‚ˆã‚Šé »ç¹ã«ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’æ›´æ–°
  // GUIDANCE_DISPLAY_DURATION ã¯ä½¿ç”¨ã—ãªã„ï¼ˆç¶™ç¶šè¡¨ç¤ºã®ãŸã‚ï¼‰

  // syncIntervalå¤‰æ•°ã¯å‰Šé™¤

  onMount(() => {
    console.log('ğŸš€ FaceDetection component mounted');

    const init = async () => {
      try {
        await initializeMediaPipe();
        if (videoElement) {
          console.log('ğŸ“¹ Video element found, starting camera...');
          await startCamera();
        } else {
          console.log('â³ Video element not ready, waiting...');
        }

        // å®šæœŸåŒæœŸãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã¯å‰Šé™¤
      } catch (error) {
        console.error('âŒ Face detection initialization failed:', error);
        dispatch('error', {
          message:
            'Face detection initialization failed: ' +
            (error instanceof Error ? error.message : String(error)),
        });
      }
    };

    init();

    // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–¢æ•°ã¯å‰Šé™¤
  });

  // Public method to reset detection state
  export function resetDetectionState() {
    console.log('ğŸ”„ Resetting face detection state');

    // Reset all detection-related variables
    stablePosition = false;
    stableFrameCount = 0;
    lastGuidanceUpdate = 0;
    showPoseGuidance = false;
    poseGuidanceMessage = '';
    poseGuidanceType = '';

    console.log('âœ… Face detection state reset completed');
  }

  onDestroy(() => {
    completeCleanup();
  });

  $: if (
    videoElement &&
    canvasElement &&
    faceMesh &&
    !camera &&
    !isStartingCamera
  ) {
    console.log('ğŸ”„ Starting camera...');
    startCamera().catch(error => {
      console.error('âŒ Camera start failed:', error);
    });
  }

  // Watch for mode changes (debug disabled)
  // $: if (currentMode) { console.log('ğŸ“± Mode changed:', currentMode); }

  async function initializeMediaPipe() {
    console.log('ğŸ”§ Initializing MediaPipe FaceMesh...');

    faceMesh = new FaceMesh({
      locateFile: (file: string) => {
        return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
      },
    });

    // Use same settings as PHP version
    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.7, // Increased from 0.5
      minTrackingConfidence: 0.7, // Increased from 0.5
      selfieMode: false,
      staticImageMode: false,
    });

    faceMesh.onResults(onResults);
    console.log('âœ… MediaPipe FaceMesh initialized');
  }

  // ã‚­ãƒ£ãƒ³ãƒã‚¹åŒæœŸæ©Ÿèƒ½ã¯å‰Šé™¤

  async function startCamera() {
    if (!videoElement || !faceMesh) {
      console.warn('âš ï¸ Cannot start camera: missing videoElement or faceMesh');
      return;
    }

    if (isStartingCamera) {
      console.log('â³ Camera is already starting, skipping...');
      return;
    }

    isStartingCamera = true;
    try {
      console.log('ğŸ“¹ Starting camera...');
      console.log('ğŸ“Š Video element state:', {
        readyState: videoElement.readyState,
        hasStream: !!videoElement.srcObject,
        videoWidth: videoElement.videoWidth,
        videoHeight: videoElement.videoHeight,
      });

      camera = new MediaPipeCamera(videoElement, {
        onFrame: async () => {
          if (faceMesh && videoElement) {
            try {
              await faceMesh.send({ image: videoElement });
            } catch (error) {
              console.warn('MediaPipe processing error:', error);
            }
          }
        },
        width: 640,
        height: 480,
      });

      await camera.start();
      console.log('âœ… Camera started successfully');
      console.log('ğŸ“Š Video element after start:', {
        readyState: videoElement.readyState,
        hasStream: !!videoElement.srcObject,
        videoWidth: videoElement.videoWidth,
        videoHeight: videoElement.videoHeight,
        currentSrc: videoElement.currentSrc,
        srcObject: videoElement.srcObject ? 'MediaStream' : 'null',
      });

      // Wait for video to be ready
      if (videoElement.readyState < 2) {
        console.log('â³ Waiting for video to be ready...');
        await new Promise(resolve => {
          const checkReady = () => {
            if (videoElement.readyState >= 2) {
              console.log('âœ… Video is now ready:', {
                readyState: videoElement.readyState,
                videoWidth: videoElement.videoWidth,
                videoHeight: videoElement.videoHeight,
              });

              resolve(true);
            } else {
              setTimeout(checkReady, 50);
            }
          };
          checkReady();
        });
      }

      // Reset detection state when camera starts
      faceDetected = false;
      faceDetectionCount = 0;
      faceDetectionStartTime = null;
      stablePosition = false;
      stableStartTime = null;
      progress = 0;

      dispatch('cameraStarted');
    } catch (error) {
      console.error('âŒ Camera startup failed:', error);
      dispatch('error', {
        message:
          'Camera startup failed: ' +
          (error instanceof Error ? error.message : String(error)),
      });
    } finally {
      isStartingCamera = false;
    }
  }

  function onResults(results: any) {
    if (!canvasCtx && canvasElement) {
      canvasCtx = canvasElement.getContext('2d')!;
    }

    if (!canvasCtx) return;

    // Clear canvas
    canvasCtx.save();
    canvasCtx.clearRect(0, 0, canvasElement!.width, canvasElement!.height);

    // Draw video with proper aspect ratio handling
    const videoWidth = results.image.width || results.image.videoWidth;
    const videoHeight = results.image.height || results.image.videoHeight;
    const canvasWidth = canvasElement!.width;
    const canvasHeight = canvasElement!.height;

    // Calculate scaling to fit video into canvas while maintaining aspect ratio
    const videoAspect = videoWidth / videoHeight;
    const canvasAspect = canvasWidth / canvasHeight;

    let drawWidth, drawHeight, drawX, drawY;

    if (videoAspect > canvasAspect) {
      // Video is wider - fit to canvas height
      drawHeight = canvasHeight;
      drawWidth = drawHeight * videoAspect;
      drawX = (canvasWidth - drawWidth) / 2;
      drawY = 0;
    } else {
      // Video is taller - fit to canvas width
      drawWidth = canvasWidth;
      drawHeight = drawWidth / videoAspect;
      drawX = 0;
      drawY = (canvasHeight - drawHeight) / 2;
    }

    canvasCtx.drawImage(results.image, drawX, drawY, drawWidth, drawHeight);

    // Debug: Log drawing dimensions (only occasionally to avoid spam)
    if (Math.random() < 0.01) {
      // 1% chance to log
      console.log('ğŸ¨ Canvas drawing debug:', {
        video: { width: videoWidth, height: videoHeight, aspect: videoAspect },
        canvas: {
          width: canvasWidth,
          height: canvasHeight,
          aspect: canvasAspect,
        },
        draw: { x: drawX, y: drawY, width: drawWidth, height: drawHeight },
      });
    }

    const hasFace =
      results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0;
    // MediaPipeçµæœã®ãƒ­ã‚°ã¯å‰Šé™¤ï¼ˆå¿…è¦æ™‚ã®ã¿æœ‰åŠ¹åŒ–ï¼‰
    // console.log('ğŸ“¸ MediaPipe results:', { hasFace, faceCount: results.multiFaceLandmarks?.length || 0 });

    if (hasFace) {
      const landmarks = results.multiFaceLandmarks[0];
      faceLandmarks = landmarks;

      // Calculate pose
      const pose = calculatePose(landmarks);
      // å§¿å‹¢è¨ˆç®—ã®ãƒ­ã‚°ã¯å‰Šé™¤ï¼ˆå¿…è¦æ™‚ã®ã¿æœ‰åŠ¹åŒ–ï¼‰
      // console.log('ğŸ“ Calculated pose:', pose);

      updateStability(pose);

      if (showMesh) {
        drawFaceMesh(landmarks);
      }

      // Face detection stability
      faceDetectionCount++;

      if (!faceDetected && faceDetectionCount >= FACE_DETECTION_THRESHOLD) {
        faceDetected = true;

        if (currentMode !== CaptureMode?.CAMERA_STARTUP) {
          faceDetectionStartTime = performance.now();
          console.log(
            'ğŸ‘¤ Face detection started at:',
            new Date().toLocaleTimeString()
          );
          // ãƒ‡ã‚¶ã‚¤ãƒ³ã«ãªã„ãŸã‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã—ãªã„
        }
      }

      // Check auto capture (exclude preview modes)
      if (
        currentMode !== CaptureMode?.CAMERA_STARTUP &&
        currentMode !== CaptureMode?.PREVIEW_BEFORE &&
        currentMode !== CaptureMode?.PREVIEW_AFTER
      ) {
        checkAutoCapture();
      }

      const guidanceInfo = {
        show: showPoseGuidance,
        message: poseGuidanceMessage,
        type: poseGuidanceType,
        direction: getGuidanceDirection(pose),
        nosePosition: getNosePosition(landmarks),
      };

      dispatch('faceDetected', {
        landmarks,
        pose,
        stable: stablePosition,
        progress,
        guidance: guidanceInfo,
      });
    } else {
      // No face detected
      // console.log('âŒ No face detected'); // ãƒ­ã‚°å‰Šé™¤
      handleNoFaceDetected();
    }

    drawUIOverlays();
    canvasCtx.restore();
  }

  function drawFaceMesh(landmarks: any) {
    if (!canvasCtx) return;

    drawConnectors(canvasCtx, landmarks, FACEMESH_TESSELATION, {
      color: '#C0C0C070',
      lineWidth: 1,
    });
    drawConnectors(canvasCtx, landmarks, FACEMESH_RIGHT_EYE, {
      color: '#FF3030',
    });
    drawConnectors(canvasCtx, landmarks, FACEMESH_LEFT_EYE, {
      color: '#30FF30',
    });
    drawConnectors(canvasCtx, landmarks, FACEMESH_FACE_OVAL, {
      color: '#E0E0E0',
    });
    drawConnectors(canvasCtx, landmarks, FACEMESH_LIPS, {
      color: '#E0E0E0',
    });
  }

  function handleNoFaceDetected() {
    faceDetectionCount = 0;

    if (faceDetected) {
      faceDetected = false;
      faceDetectionStartTime = null;
    }

    stablePosition = false;
    stableStartTime = null;
    progress = 0;

    // Clear pose guidance in CAMERA_STARTUP mode
    if (currentMode === CaptureMode?.CAMERA_STARTUP) {
      showPoseGuidance = false;
      poseGuidanceMessage = '';
    }

    // ãƒ‡ã‚¶ã‚¤ãƒ³ã«ãªã„ãŸã‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯é€ä¿¡ã—ãªã„

    dispatch('faceDetected', {
      landmarks: null,
      pose: null,
      stable: false,
      progress: 0,
    });

    showPoseGuidance = false;
    lastGuidanceMessage = '';
  }

  function calculateFaceSize(landmarks: any): number {
    try {
      // é¡”ã®å¢ƒç•Œã‚’è¨ˆç®—
      let minX = 1,
        maxX = 0,
        minY = 1,
        maxY = 0;

      // é¡”ã®è¼ªéƒ­ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦å¢ƒç•Œã‚’è¨ˆç®—
      const faceContourIndices = [
        10, 151, 9, 8, 168, 6, 197, 195, 5, 4, 1, 19, 94, 125, 142, 36, 205,
        206, 207, 213, 192, 147, 187, 207, 206, 205, 36, 142, 125, 94, 19, 1, 4,
        5, 195, 197, 6, 168, 8, 9, 151, 10,
      ];

      for (const index of faceContourIndices) {
        if (landmarks[index]) {
          minX = Math.min(minX, landmarks[index].x);
          maxX = Math.max(maxX, landmarks[index].x);
          minY = Math.min(minY, landmarks[index].y);
          maxY = Math.max(maxY, landmarks[index].y);
        }
      }

      // é¡”ã®ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ï¼ˆç”»åƒã«å¯¾ã™ã‚‹ç›¸å¯¾ã‚µã‚¤ã‚ºï¼‰
      const faceWidth = maxX - minX;
      const faceHeight = maxY - minY;
      const faceSize = Math.sqrt(
        faceWidth * faceWidth + faceHeight * faceHeight
      );

      return faceSize;
    } catch (error) {
      console.warn('Face size calculation error:', error);
      return 0;
    }
  }

  function calculatePose(landmarks: any) {
    // PHPç‰ˆã¨åŒã˜å§¿å‹¢è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
    try {
      // é¡”ã®ä¸»è¦ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—ï¼ˆMediaPipe FaceMeshæ¨™æº–ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰
      const nose = landmarks[1]; // é¼»å…ˆ
      const leftEye = landmarks[33]; // å·¦ç›®å†…å´
      const rightEye = landmarks[263]; // å³ç›®å†…å´
      const chin = landmarks[175]; // é¡
      const forehead = landmarks[10]; // é¡ä¸­å¤®

      if (!nose || !leftEye || !rightEye || !chin || !forehead) {
        throw new Error('Required landmarks not found');
      }

      // Rollï¼ˆå·¦å³ã®å‚¾ãï¼‰ã‚’è¨ˆç®— - ç›®ã®æ°´å¹³ç·šã‹ã‚‰
      const eyeVector = {
        x: rightEye.x - leftEye.x,
        y: rightEye.y - leftEye.y,
      };
      const roll = Math.atan2(eyeVector.y, eyeVector.x) * (180 / Math.PI);

      // Pitchï¼ˆä¸Šä¸‹ã®å‘ãï¼‰ã‚’è¨ˆç®— - é¡”ã®ç¸¦æ–¹å‘ã‹ã‚‰
      const faceHeight = Math.abs(chin.y - forehead.y);
      const noseOffset = nose.y - (forehead.y + chin.y) / 2;
      const pitch = Math.atan2(noseOffset, faceHeight) * (180 / Math.PI);

      // Yawï¼ˆå·¦å³ã®å‘ãï¼‰ã‚’è¨ˆç®— - é¼»ã®ä½ç½®ã‹ã‚‰
      const eyeCenter = {
        x: (leftEye.x + rightEye.x) / 2,
        y: (leftEye.y + rightEye.y) / 2,
      };
      const noseOffset_x = nose.x - eyeCenter.x;
      const eyeDistance = Math.sqrt(
        eyeVector.x * eyeVector.x + eyeVector.y * eyeVector.y
      );
      const yaw = Math.atan2(noseOffset_x, eyeDistance) * (180 / Math.PI);

      // é¡”ã®ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
      const faceSize = calculateFaceSize(landmarks);

      // è·é›¢ã¨å“è³ªã®è¨ˆç®—ï¼ˆã‚ˆã‚Šå³å¯†ã«ï¼‰
      const distance = Math.max(0.5, Math.min(2.0, 1.0 / eyeDistance));
      const quality = Math.max(0.0, Math.min(1.0, faceSize * 2)); // Face size based quality

      const result = {
        roll: Math.round(roll * 10) / 10,
        pitch: Math.round(pitch * 10) / 10,
        yaw: Math.round(yaw * 10) / 10,
        distance: Math.round(distance * 100) / 100,
        quality: Math.round(quality * 100) / 100,
        faceSize: Math.round(faceSize * 1000) / 1000,
      };

      return result;
    } catch (error) {
      console.warn('Pose calculation error:', error);
      return {
        roll: 0,
        pitch: 0,
        yaw: 0,
        distance: 1.0,
        quality: 0.0,
        faceSize: 0.0,
      };
    }
  }

  function updateStability(pose: any) {
    const now = performance.now();

    // PHPç‰ˆã¨åŒã˜å³ã—ã„æ¡ä»¶
    const isGoodPose =
      Math.abs(pose.roll) < THRESHOLDS.roll &&
      Math.abs(pose.pitch) < THRESHOLDS.pitch &&
      Math.abs(pose.yaw) < THRESHOLDS.yaw &&
      pose.quality >= MIN_FACE_QUALITY &&
      pose.faceSize >= MIN_FACE_SIZE;

    // å§¿å‹¢å®‰å®šæ€§ãƒã‚§ãƒƒã‚¯ã®ãƒ­ã‚°ã¯å‰Šé™¤ï¼ˆå¿…è¦æ™‚ã®ã¿æœ‰åŠ¹åŒ–ï¼‰
    // console.log('ğŸ¯ Pose stability check:', { roll: pose.roll.toFixed(1), pitch: pose.pitch.toFixed(1), yaw: pose.yaw.toFixed(1), isGoodPose, progress: progress.toFixed(1) });

    if (isGoodPose) {
      if (!stablePosition) {
        stablePosition = true;
        stableStartTime = now;
        showPoseGuidance = true;
        poseGuidanceMessage = 'è‰¯ã„å§¿å‹¢ã§ã™ï¼ä¿æŒã—ã¦ãã ã•ã„';
        poseGuidanceType = 'success';
        console.log('âœ… Stable position achieved!');

        // æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯2ç§’å¾Œã«éè¡¨ç¤ºã«ã™ã‚‹
        setTimeout(() => {
          if (stablePosition) {
            showPoseGuidance = false;
          }
        }, 2000);
      }

      if (stableStartTime) {
        const elapsed = (now - stableStartTime) / 1000;
        // ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’å§¿å‹¢å®‰å®šå¾Œã®è‡ªå‹•æ’®å½±å¾…æ©Ÿæ™‚é–“ï¼ˆFACE_DETECTION_DELAYï¼‰ã«åˆã‚ã›ã‚‹
        progress = Math.min((elapsed / FACE_DETECTION_DELAY) * 100, 100);

        if (progress >= 100) {
          console.log('ğŸ‰ Auto capture countdown completed!');
        }
      }
    } else {
      if (stablePosition) {
        console.log('âŒ Lost stable position');
      }
      stablePosition = false;
      stableStartTime = null;
      progress = 0;

      // Guidance messages
      if (now - lastGuidanceUpdate > GUIDANCE_UPDATE_INTERVAL) {
        updatePoseGuidance(pose);
        lastGuidanceUpdate = now;
      }
    }
  }

  function getGuidanceDirection(pose: any) {
    if (!pose) return null;

    // é¡”ã®å“è³ªãŒä½ã„å ´åˆã¯çŸ¢å°ã‚’è¡¨ç¤ºã—ãªã„
    if (pose.quality < MIN_FACE_QUALITY) {
      return null;
    }

    // å§¿å‹¢ã«åŸºã¥ã„ã¦çŸ¢å°ã®æ–¹å‘ã‚’æ±ºå®š
    if (Math.abs(pose.roll) >= THRESHOLDS.roll) {
      return pose.roll > 0 ? 'tilt-left' : 'tilt-right';
    } else if (Math.abs(pose.pitch) >= THRESHOLDS.pitch) {
      return pose.pitch > 0 ? 'look-up' : 'look-down';
    } else if (Math.abs(pose.yaw) >= THRESHOLDS.yaw) {
      return pose.yaw > 0 ? 'turn-left' : 'turn-right';
    }
    return null;
  }

  // PHPã¨åŒã˜é¼»ã®ä½ç½®è¨ˆç®—ï¼ˆå®Œå…¨ç§»æ¤ç‰ˆï¼‰
  function getNosePosition(landmarks: any) {
    if (!landmarks || !canvasElement) return null;

    // é¼»ã®å…ˆç«¯ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹1ï¼‰
    const nose = landmarks[1];
    if (!nose) return null;

    // PHPã®å®Ÿè£…ã¨å®Œå…¨ã«åŒã˜åº§æ¨™å¤‰æ›
    // const noseX = (1 - nose.x) * outputCanvas.width;
    // const noseY = nose.y * outputCanvas.height;
    const noseX = (1 - nose.x) * canvasElement.width;
    const noseY = nose.y * canvasElement.height;

    // è¡¨ç¤ºã‚µã‚¤ã‚ºã«åˆã‚ã›ã¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    const canvasRect = canvasElement.getBoundingClientRect();
    const scaleX = canvasRect.width / canvasElement.width;
    const scaleY = canvasRect.height / canvasElement.height;

    const displayX = noseX * scaleX;
    const displayY = noseY * scaleY;

    return { x: displayX, y: displayY };
  }

  function updatePoseGuidance(pose: any) {
    // Don't show pose guidance in CAMERA_STARTUP mode
    if (currentMode === CaptureMode?.CAMERA_STARTUP) {
      return;
    }

    let message = '';
    let type = 'warning';

    // ã‚ˆã‚Šè©³ç´°ã§è¦ªåˆ‡ãªã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆPHPç‰ˆã¨åŒã˜å„ªå…ˆé †ä½ï¼‰
    if (pose.faceSize < MIN_FACE_SIZE) {
      message = 'ã‚«ãƒ¡ãƒ©ã«è¿‘ã¥ã„ã¦ãã ã•ã„ï¼ˆé¡”ãŒå°ã•ã™ãã¾ã™ï¼‰';
      type = 'error';
    } else if (pose.quality < MIN_FACE_QUALITY) {
      message = 'é¡”å…¨ä½“ã‚’ã‚«ãƒ¡ãƒ©ã«å‘ã‘ã¦ãã ã•ã„';
      type = 'error';
    } else if (Math.abs(pose.roll) >= THRESHOLDS.roll) {
      message =
        pose.roll > 0
          ? 'é ­ã‚’å·¦ã«å°‘ã—å‚¾ã‘ã¦ãã ã•ã„'
          : 'é ­ã‚’å³ã«å°‘ã—å‚¾ã‘ã¦ãã ã•ã„';
    } else if (Math.abs(pose.pitch) >= THRESHOLDS.pitch) {
      message =
        pose.pitch > 0
          ? 'é¡”ã‚’å°‘ã—ä¸Šã«å‘ã‘ã¦ãã ã•ã„'
          : 'é¡”ã‚’å°‘ã—ä¸‹ã«å‘ã‘ã¦ãã ã•ã„';
    } else if (Math.abs(pose.yaw) >= THRESHOLDS.yaw) {
      message =
        pose.yaw > 0 ? 'é¡”ã‚’å³ã«å‘ã‘ã¦ãã ã•ã„' : 'é¡”ã‚’å·¦ã«å‘ã‘ã¦ãã ã•ã„';
    } else {
      message = 'å®Œç’§ãªå§¿å‹¢ã§ã™ï¼ã“ã®çŠ¶æ…‹ã‚’ä¿æŒã—ã¦ãã ã•ã„';
      type = 'success';
    }

    if (message) {
      poseGuidanceMessage = message;
      poseGuidanceType = type;
      showPoseGuidance = true;
      lastGuidanceMessage = message;

      // å§¿å‹¢ãŒæ‚ªã„é–“ã¯ç¶™ç¶šçš„ã«è¡¨ç¤ºï¼ˆåŒã˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã‚‚ç¶™ç¶šè¡¨ç¤ºï¼‰
    }
  }

  function checkAutoCapture() {
    if (!faceDetected || !stableStartTime) return;

    // å§¿å‹¢ãŒå®‰å®šã—ã¦ã‹ã‚‰ã®çµŒéæ™‚é–“ã‚’è¨ˆç®—
    const elapsed = (performance.now() - stableStartTime) / 1000;

    console.log('Auto capture check:', {
      elapsed: elapsed.toFixed(2),
      required: FACE_DETECTION_DELAY,
      stablePosition,
      progress: progress.toFixed(1),
      currentMode,
    });

    // å§¿å‹¢ãŒå®‰å®šã—ã¦ã‹ã‚‰3ç§’çµŒéã§æ’®å½±
    if (elapsed >= FACE_DETECTION_DELAY && stablePosition && progress >= 100) {
      console.log('ğŸ¯ Auto capture triggered!');
      dispatch('autoCapture', { landmarks: faceLandmarks });

      // Reset detection to prevent multiple captures
      faceDetectionStartTime = null;
      faceDetected = false;
      stablePosition = false;
      stableStartTime = null;
      progress = 0;
    }
  }

  function drawUIOverlays() {
    if (!canvasCtx || !canvasElement) return;

    // Save the current transformation matrix
    canvasCtx.save();

    // ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®ã¿æç”»ï¼ˆç™½ã„å††ã¯CSSã§è¡¨ç¤ºï¼‰
    if (
      currentMode !== CaptureMode?.CAMERA_STARTUP &&
      faceDetected &&
      stablePosition &&
      progress > 0
    ) {
      const centerX = canvasElement.width / 2;
      const centerY = canvasElement.height / 2;
      // CSS ã®ãƒã‚¹ã‚¯å††ã¨åŒã˜ã‚µã‚¤ã‚ºã«åˆã‚ã›ã‚‹ï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–å¯¾å¿œï¼‰
      const circleSize = Math.min(300, window.innerWidth * 0.5);
      const radius = circleSize / 2 - 10; // ãƒã‚¹ã‚¯å††ã®å†…å´ã«ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æç”»

      const progressAngle = (progress / 100) * 2 * Math.PI - Math.PI / 2;

      canvasCtx.beginPath();
      canvasCtx.arc(centerX, centerY, radius, -Math.PI / 2, progressAngle);
      canvasCtx.strokeStyle = progress >= 100 ? '#4CAF50' : '#FFA500';
      canvasCtx.lineWidth = 8;
      canvasCtx.stroke();
    }

    // Restore the transformation matrix
    canvasCtx.restore();
  }

  function cleanup() {
    console.log('ğŸ”„ Cleaning up camera and face detection resources');

    // Stop camera but don't destroy faceMesh (for reuse)
    if (camera) {
      camera.stop();
      camera = null;
    }

    // Stop video stream
    if (videoElement && videoElement.srcObject) {
      const stream = videoElement.srcObject as MediaStream;
      stream.getTracks().forEach(track => {
        track.stop();
        console.log('ğŸ›‘ Stopped camera track:', track.kind);
      });
      videoElement.srcObject = null;
    }

    // Reset detection state
    faceDetected = false;
    faceDetectionCount = 0;
    faceDetectionStartTime = null;
    stablePosition = false;
    stableStartTime = null;
    progress = 0;
    isStartingCamera = false;

    console.log('âœ… Camera cleanup completed (faceMesh preserved for reuse)');
  }

  // Complete cleanup function for component destruction
  function completeCleanup() {
    console.log('ğŸ—‘ï¸ Complete cleanup - destroying all resources');
    cleanup();

    if (faceMesh) {
      faceMesh.close();
      faceMesh = null;
    }
  }

  // Export cleanup functions for external use
  export { cleanup, completeCleanup };

  // Export function to get current face landmarks
  export function getCurrentFaceLandmarks() {
    return faceLandmarks;
  }

  // ã‚­ãƒ£ãƒ³ãƒã‚¹åŒæœŸæ©Ÿèƒ½ã¯å‰Šé™¤

  // Export guidance state
  export { showPoseGuidance, poseGuidanceMessage, poseGuidanceType };
</script>

<!-- This component doesn't render anything directly -->
<!-- It only handles face detection logic and dispatches events -->
